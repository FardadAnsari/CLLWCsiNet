{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import sys\n",
    "import traceback\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import traceback\n",
    "import scipy.io as sio\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from collections import OrderedDict\n",
    "\n",
    "#from utils import logger\n",
    "\n",
    "__all__ = [\"acrnet\"]\n",
    "\n",
    "\n",
    "class ConvBN(nn.Sequential):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, groups=1):\n",
    "        if not isinstance(kernel_size, int):\n",
    "            padding = [(i - 1) // 2 for i in kernel_size]\n",
    "        else:\n",
    "            padding = (kernel_size - 1) // 2\n",
    "        super(ConvBN, self).__init__(OrderedDict([\n",
    "            ('conv', nn.Conv2d(in_channels=in_planes,\n",
    "                               out_channels=out_planes,\n",
    "                               kernel_size=kernel_size,\n",
    "                               stride=stride,\n",
    "                               padding=padding,\n",
    "                               groups=groups,\n",
    "                               bias=False)),\n",
    "            ('bn', nn.BatchNorm2d(out_planes))\n",
    "        ]))\n",
    "\n",
    "\n",
    "class ACRDecoderBlock(nn.Module):\n",
    "    r\"\"\" Inverted residual with extensible width and group conv\n",
    "    \"\"\"\n",
    "    def __init__(self, expansion):\n",
    "        super(ACRDecoderBlock, self).__init__()\n",
    "        width = 8 * expansion\n",
    "        self.conv1_bn = ConvBN(2, width, [1, 9])\n",
    "        self.prelu1 = nn.PReLU(num_parameters=width, init=0.3)\n",
    "        self.conv2_bn = ConvBN(width, width, 7, groups=4 * expansion)\n",
    "        self.prelu2 = nn.PReLU(num_parameters=width, init=0.3)\n",
    "        self.conv3_bn = ConvBN(width, 2, [9, 1])\n",
    "        self.prelu3 = nn.PReLU(num_parameters=2, init=0.3)\n",
    "        self.identity = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.identity(x)\n",
    "\n",
    "        residual = self.prelu1(self.conv1_bn(x))\n",
    "        residual = self.prelu2(self.conv2_bn(residual))\n",
    "        residual = self.conv3_bn(residual)\n",
    "\n",
    "        return self.prelu3(identity + residual)\n",
    "\n",
    "\n",
    "class ACREncoderBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ACREncoderBlock, self).__init__()\n",
    "        self.conv_bn1 = ConvBN(2, 2, [1, 9])\n",
    "        self.prelu1 = nn.PReLU(num_parameters=2, init=0.3)\n",
    "        self.conv_bn2 = ConvBN(2, 2, [9, 1])\n",
    "        self.prelu2 = nn.PReLU(num_parameters=2, init=0.3)\n",
    "        self.identity = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.identity(x)\n",
    "\n",
    "        residual = self.prelu1(self.conv_bn1(x))\n",
    "        residual = self.conv_bn2(residual)\n",
    "\n",
    "        return self.prelu2(identity + residual)\n",
    "\n",
    "\n",
    "class ACRNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels=2,\n",
    "                 reduction=4,\n",
    "                 expansion=1):\n",
    "        super(ACRNet, self).__init__()\n",
    "        #logger.info(f\"=> Model ACRNet with reduction={reduction}, expansion={expansion}\")\n",
    "        total_size, w, h = 2048, 32, 32\n",
    "\n",
    "        self.encoder_feature = nn.Sequential(OrderedDict([\n",
    "            (\"conv5x5_bn\", ConvBN(in_channels, 2, 5)),\n",
    "            (\"prelu\", nn.PReLU(num_parameters=2, init=0.3)),\n",
    "            (\"ACREncoderBlock1\", ACREncoderBlock()),\n",
    "            (\"ACREncoderBlock2\", ACREncoderBlock()),\n",
    "        ]))\n",
    "        self.encoder_fc = nn.Linear(total_size, total_size // reduction)\n",
    "\n",
    "        self.decoder_fc = nn.Linear(total_size // reduction, total_size)\n",
    "        self.decoder_feature = nn.Sequential(OrderedDict([\n",
    "            (\"conv5x5_bn\", ConvBN(2, in_channels, 5)),\n",
    "            (\"prelu\", nn.PReLU(num_parameters=2, init=0.3)),\n",
    "            (\"ACRDecoderBlock1\", ACRDecoderBlock(expansion=expansion)),\n",
    "            (\"ACRDecoderBlock2\", ACRDecoderBlock(expansion=expansion)),\n",
    "            (\"sigmoid\", nn.Sigmoid())\n",
    "        ]))\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    # def adding_noise(self,x):\n",
    "    #     # Compute signal power\n",
    "    #     signal_power = torch.mean(x**2)\n",
    "\n",
    "    #     # Define the desired SNR in dB (e.g., 20 dB)\n",
    "    #     SNR_dB = 40\n",
    "\n",
    "    #     # Compute the SNR in linear scale\n",
    "    #     SNR_linear = 10**(SNR_dB / 10)\n",
    "\n",
    "    #     # Compute the noise power based on the SNR\n",
    "    #     noise_power = signal_power / SNR_linear\n",
    "\n",
    "    #     # Generate Gaussian noise with the same shape as the input tensor\n",
    "    #     noise = torch.randn_like(x) * torch.sqrt(noise_power)\n",
    "\n",
    "    #     # Add the noise to the input tensor\n",
    "    #     x_noisy = x + noise\n",
    "\n",
    "    #     return x_noisy\n",
    "\n",
    "    def forward(self, x):\n",
    "        n, c, h, w = x.detach().size()\n",
    "\n",
    "        out = self.encoder_feature(x)\n",
    "        out = self.encoder_fc(out.view(n, -1))\n",
    "        #out= self.adding_noise(out)\n",
    "        out = self.decoder_fc(out)\n",
    "        out = self.decoder_feature(out.view(n, c, h, w))\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "def acrnet(reduction=4, expansion=1):\n",
    "    r\"\"\" Create an ACRNet architecture.\n",
    "    \"\"\"\n",
    "    model = ACRNet(reduction=reduction, expansion=expansion)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = acrnet(reduction=8,\n",
    "                   expansion=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1053512"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#from Trans_Net.utils import *\n",
    "\n",
    "\n",
    "state_dict = torch.load(r'table1-20240523T203416Z-001\\table1\\cr8\\1x_out\\model.pth',map_location=torch.device('cpu'))['state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ACRNet(\n",
       "  (encoder_feature): Sequential(\n",
       "    (conv5x5_bn): ConvBN(\n",
       "      (conv): Conv2d(2, 2, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (prelu): PReLU(num_parameters=2)\n",
       "    (ACREncoderBlock1): ACREncoderBlock(\n",
       "      (conv_bn1): ConvBN(\n",
       "        (conv): Conv2d(2, 2, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4), bias=False)\n",
       "        (bn): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (prelu1): PReLU(num_parameters=2)\n",
       "      (conv_bn2): ConvBN(\n",
       "        (conv): Conv2d(2, 2, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
       "        (bn): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (prelu2): PReLU(num_parameters=2)\n",
       "      (identity): Identity()\n",
       "    )\n",
       "    (ACREncoderBlock2): ACREncoderBlock(\n",
       "      (conv_bn1): ConvBN(\n",
       "        (conv): Conv2d(2, 2, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4), bias=False)\n",
       "        (bn): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (prelu1): PReLU(num_parameters=2)\n",
       "      (conv_bn2): ConvBN(\n",
       "        (conv): Conv2d(2, 2, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
       "        (bn): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (prelu2): PReLU(num_parameters=2)\n",
       "      (identity): Identity()\n",
       "    )\n",
       "  )\n",
       "  (encoder_fc): Linear(in_features=2048, out_features=256, bias=True)\n",
       "  (decoder_fc): Linear(in_features=256, out_features=2048, bias=True)\n",
       "  (decoder_feature): Sequential(\n",
       "    (conv5x5_bn): ConvBN(\n",
       "      (conv): Conv2d(2, 2, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (prelu): PReLU(num_parameters=2)\n",
       "    (ACRDecoderBlock1): ACRDecoderBlock(\n",
       "      (conv1_bn): ConvBN(\n",
       "        (conv): Conv2d(2, 8, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4), bias=False)\n",
       "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (prelu1): PReLU(num_parameters=8)\n",
       "      (conv2_bn): ConvBN(\n",
       "        (conv): Conv2d(8, 8, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=4, bias=False)\n",
       "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (prelu2): PReLU(num_parameters=8)\n",
       "      (conv3_bn): ConvBN(\n",
       "        (conv): Conv2d(8, 2, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
       "        (bn): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (prelu3): PReLU(num_parameters=2)\n",
       "      (identity): Identity()\n",
       "    )\n",
       "    (ACRDecoderBlock2): ACRDecoderBlock(\n",
       "      (conv1_bn): ConvBN(\n",
       "        (conv): Conv2d(2, 8, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4), bias=False)\n",
       "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (prelu1): PReLU(num_parameters=8)\n",
       "      (conv2_bn): ConvBN(\n",
       "        (conv): Conv2d(8, 8, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=4, bias=False)\n",
       "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (prelu2): PReLU(num_parameters=8)\n",
       "      (conv3_bn): ConvBN(\n",
       "        (conv): Conv2d(8, 2, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
       "        (bn): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (prelu3): PReLU(num_parameters=2)\n",
       "      (identity): Identity()\n",
       "    )\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Python312\\Lib\\site-packages\\torch\\ao\\quantization\\observer.py:220: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.qconfig = torch.quantization.get_default_qconfig('fbgemm')  # Set quantization config\n",
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    model, {nn.Linear}, dtype=torch.qint8  # Adjust the module types as per your model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.0000e+00, 1.0000e+00, 4.1690e-21,  ..., 5.9008e-07,\n",
       "           7.2361e-18, 9.8408e-03],\n",
       "          [2.6706e-04, 1.0000e+00, 1.7767e-14,  ..., 6.9955e-05,\n",
       "           1.0000e+00, 1.5051e-12],\n",
       "          [2.0212e-06, 1.0000e+00, 5.2710e-20,  ..., 9.9554e-01,\n",
       "           7.9297e-01, 1.8407e-02],\n",
       "          ...,\n",
       "          [8.0232e-03, 1.0000e+00, 1.6108e-21,  ..., 3.1334e-04,\n",
       "           7.4424e-15, 2.1634e-02],\n",
       "          [7.1752e-02, 1.0000e+00, 2.3027e-23,  ..., 2.0851e-25,\n",
       "           1.0000e+00, 9.5169e-01],\n",
       "          [3.7186e-02, 4.7552e-01, 2.3420e-03,  ..., 1.0000e+00,\n",
       "           3.9448e-17, 2.4609e-03]],\n",
       "\n",
       "         [[1.0000e+00, 1.0000e+00, 2.5777e-02,  ..., 1.0000e+00,\n",
       "           2.4086e-05, 8.6777e-02],\n",
       "          [2.0947e-06, 7.2427e-07, 1.0000e+00,  ..., 1.2921e-05,\n",
       "           1.0000e+00, 7.9201e-03],\n",
       "          [6.5722e-05, 7.3321e-07, 9.1663e-01,  ..., 3.3119e-04,\n",
       "           1.0000e+00, 2.2533e-04],\n",
       "          ...,\n",
       "          [4.3339e-03, 8.5360e-10, 1.0000e+00,  ..., 9.9247e-01,\n",
       "           1.0000e+00, 1.6152e-01],\n",
       "          [4.1628e-05, 1.5876e-07, 1.0000e+00,  ..., 1.0000e+00,\n",
       "           2.3210e-04, 4.6476e-02],\n",
       "          [5.4440e-01, 1.7089e-02, 7.6969e-01,  ..., 2.6516e-31,\n",
       "           9.7377e-01, 6.3527e-01]]]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For simplicity, I'm using a dummy input for calibration\n",
    "dummy_input = torch.randn(1, 2, 32, 32)  # Modify according to your input shape\n",
    "quantized_model(dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ACRNet(\n",
       "  (encoder_feature): Sequential(\n",
       "    (conv5x5_bn): ConvBN(\n",
       "      (conv): Conv2d(2, 2, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (prelu): PReLU(num_parameters=2)\n",
       "    (ACREncoderBlock1): ACREncoderBlock(\n",
       "      (conv_bn1): ConvBN(\n",
       "        (conv): Conv2d(2, 2, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4), bias=False)\n",
       "        (bn): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (prelu1): PReLU(num_parameters=2)\n",
       "      (conv_bn2): ConvBN(\n",
       "        (conv): Conv2d(2, 2, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
       "        (bn): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (prelu2): PReLU(num_parameters=2)\n",
       "      (identity): Identity()\n",
       "    )\n",
       "    (ACREncoderBlock2): ACREncoderBlock(\n",
       "      (conv_bn1): ConvBN(\n",
       "        (conv): Conv2d(2, 2, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4), bias=False)\n",
       "        (bn): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (prelu1): PReLU(num_parameters=2)\n",
       "      (conv_bn2): ConvBN(\n",
       "        (conv): Conv2d(2, 2, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
       "        (bn): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (prelu2): PReLU(num_parameters=2)\n",
       "      (identity): Identity()\n",
       "    )\n",
       "  )\n",
       "  (encoder_fc): DynamicQuantizedLinear(in_features=2048, out_features=256, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "  (decoder_fc): DynamicQuantizedLinear(in_features=256, out_features=2048, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "  (decoder_feature): Sequential(\n",
       "    (conv5x5_bn): ConvBN(\n",
       "      (conv): Conv2d(2, 2, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (prelu): PReLU(num_parameters=2)\n",
       "    (ACRDecoderBlock1): ACRDecoderBlock(\n",
       "      (conv1_bn): ConvBN(\n",
       "        (conv): Conv2d(2, 8, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4), bias=False)\n",
       "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (prelu1): PReLU(num_parameters=8)\n",
       "      (conv2_bn): ConvBN(\n",
       "        (conv): Conv2d(8, 8, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=4, bias=False)\n",
       "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (prelu2): PReLU(num_parameters=8)\n",
       "      (conv3_bn): ConvBN(\n",
       "        (conv): Conv2d(8, 2, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
       "        (bn): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (prelu3): PReLU(num_parameters=2)\n",
       "      (identity): Identity()\n",
       "    )\n",
       "    (ACRDecoderBlock2): ACRDecoderBlock(\n",
       "      (conv1_bn): ConvBN(\n",
       "        (conv): Conv2d(2, 8, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4), bias=False)\n",
       "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (prelu1): PReLU(num_parameters=8)\n",
       "      (conv2_bn): ConvBN(\n",
       "        (conv): Conv2d(8, 8, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=4, bias=False)\n",
       "        (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (prelu2): PReLU(num_parameters=8)\n",
       "      (conv3_bn): ConvBN(\n",
       "        (conv): Conv2d(8, 2, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
       "        (bn): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (prelu3): PReLU(num_parameters=2)\n",
       "      (identity): Identity()\n",
       "    )\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized_model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss().to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "envir = 'outdoor'  # 'indoor' or 'outdoor'\n",
    "# image params\n",
    "img_height = 32\n",
    "img_width = 32\n",
    "img_channels = 2\n",
    "img_total = img_height * img_width * img_channels\n",
    "# network params\n",
    "#residual_num = 2\n",
    "encoded_dim = 512  # compress rate=1/4->dim.=512, compress rate=1/16->dim.=128, compress rate=1/32->dim.=64, compress rate=1/64->dim.=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# envir = 'indoor'  # 'indoor' or 'outdoor'\n",
    "# # image params\n",
    "# img_height = 32\n",
    "# img_width = 32\n",
    "# img_channels = 2\n",
    "# img_total = img_height * img_width * img_channels\n",
    "# # network params\n",
    "# residual_num = 2\n",
    "# encoded_dim = 512  # compress rate=1/4->dim.=512, compress rate=1/16->dim.=128, compress rate=1/32->dim.=64, compress rate=1/64->dim.=32\n",
    "# Data loading\n",
    "if envir == 'indoor':\n",
    "    mat = sio.loadmat(r'archive\\DATA_Htrainin.mat')\n",
    "    x_train = mat['HT']  # array\n",
    "    mat = sio.loadmat(r'archive\\DATA_Hvalin.mat')\n",
    "    x_val = mat['HT']  # array\n",
    "    mat = sio.loadmat(r'archive\\DATA_Htestin.mat')\n",
    "    x_test = mat['HT']  # array\n",
    "    mat = sio.loadmat(r'archive\\DATA_HtestFin_all.mat')\n",
    "    X_test = mat['HF_all']  # array\n",
    "\n",
    "elif envir == 'outdoor':\n",
    "    mat = sio.loadmat(r'archive\\DATA_Htrainout.mat')\n",
    "    x_train = mat['HT']  # array\n",
    "    mat = sio.loadmat(r'archive\\DATA_Hvalout.mat')\n",
    "    x_val = mat['HT']  # array\n",
    "    mat = sio.loadmat(r'archive\\DATA_Htestout.mat')\n",
    "    x_test = mat['HT']  # array\n",
    "    mat = sio.loadmat(r'archive\\DATA_HtestFout_all.mat')\n",
    "    X_test = mat['HF_all']  # array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_val = x_val.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train_length = len(x_train)\n",
    "x_val_length = len(x_val)\n",
    "x_test_length = len(x_test)\n",
    "\n",
    "x_train = np.reshape(x_train, (x_train_length, img_channels, img_height, img_width))  # adapt this if using `channels_first` image data format\n",
    "x_val = np.reshape(x_val, (x_val_length, img_channels, img_height, img_width))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (x_test_length, img_channels, img_height, img_width))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "x_train = torch.tensor(x_train)\n",
    "x_val = torch.tensor(x_val)\n",
    "x_test = torch.tensor(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20000, 2, 32, 32])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 32\n",
    "img_width = 32\n",
    "img_channels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMSE is  -7.203752282535962\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "with torch.no_grad():\n",
    "\n",
    "    #torch.cuda.empty_cache()\n",
    "    quantized_model.eval()\n",
    "    device='cpu'\n",
    "    x_hat = quantized_model(x_test)\n",
    "    #torch.quantization.convert(quantized_model, inplace=True)\n",
    "    x_test = x_test.to('cpu')\n",
    "    x_hat=x_hat.to('cpu')\n",
    "\n",
    "    # Calcaulating the NMSE and rho\n",
    "    # if envir == 'indoor':\n",
    "    #     mat = sio.loadmat('D:\\Cost2100\\DATA_HtestFin_all.mat')\n",
    "    #     X_test = mat['HF_all']  # array\n",
    "\n",
    "    # elif envir == 'outdoor':\n",
    "    #     mat = sio.loadmat('D:\\Cost2100\\DATA_HtestFout_all.mat')\n",
    "    #     X_test = mat['HF_all']  # array\n",
    "\n",
    "    #X_test = torch.tensor(X_test)\n",
    "    #X_test = torch.reshape(X_test, (len(X_test), img_height, 125))\n",
    "    x_test_real = torch.reshape(x_test[:, 0, :, :], (len(x_test), -1))\n",
    "    x_test_imag = torch.reshape(x_test[:, 1, :, :], (len(x_test), -1))\n",
    "    x_test_C = x_test_real - 0.5 + 1j * (x_test_imag - 0.5)\n",
    "    x_hat_real = torch.reshape(x_hat[:, 0, :, :], (len(x_hat), -1))\n",
    "    x_hat_imag = torch.reshape(x_hat[:, 1, :, :], (len(x_hat), -1))\n",
    "    x_hat_C = x_hat_real - 0.5 + 1j * (x_hat_imag - 0.5)\n",
    "    x_hat_F = torch.reshape(x_hat_C, (len(x_hat_C), img_height, img_width))\n",
    "    X_hat = torch.fft.fft(torch.cat((x_hat_F, torch.zeros((len(x_hat_C), img_height, 257 - img_width))), axis=2), axis=2)\n",
    "    X_hat = X_hat[:, :, 0:125]\n",
    "\n",
    "    #n1 = torch.sqrt(torch.sum(torch.conj(X_test) * X_test, axis=1))\n",
    "    #n2 = torch.sqrt(torch.sum(torch.conj(X_hat) * X_hat, axis=1))\n",
    "    #aa = abs(torch.sum(torch.conj(X_test) * X_hat, axis=1))\n",
    "    #rho = torch.mean(aa / (n1 * n2), axis=1)\n",
    "    X_hat = torch.reshape(X_hat, (len(X_hat), -1))\n",
    "    #X_test = torch.reshape(X_test, (len(X_test), -1))\n",
    "    power = torch.sum(abs(x_test_C) ** 2, axis=1)\n",
    "    power_d = torch.sum(abs(X_hat) ** 2, axis=1)\n",
    "    mse = torch.sum(abs(x_test_C - x_hat_C) ** 2, axis=1)\n",
    "    NMSE = 10 * math.log10(torch.mean(mse / power))\n",
    "    #Correlation = torch.mean(rho).item().real\n",
    "\n",
    "    # print(\"In \" + envir + \" environment\")\n",
    "    # print(\"When dimension is\", encoded_dim)\n",
    "    print(\"NMSE is \", NMSE)\n",
    "    #print(\"Correlation is \", Correlation)\n",
    "#\n",
    "# file = 'CsiNet_' + (envir) + '_dim' + str(encoded_dim) + time.strftime('_%m_%d_%H_%M')\n",
    "# outfile = \"result/result_%s.mat\" % file\n",
    "# savemat(outfile, {'train_loss_history': train_loss_history,\n",
    "#                   'val_loss_history': val_loss_history,\n",
    "#                   'training_time': training_time,\n",
    "#                   'NMSE': NMSE,\n",
    "#                   'Correlation': Correlation})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
