{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datetime import datetime\nimport sys\nimport traceback\nimport numpy as np\nfrom datetime import datetime\nimport sys\nimport traceback\nimport scipy.io as sio\nimport torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:41:53.827337Z","iopub.execute_input":"2025-04-28T12:41:53.827822Z","iopub.status.idle":"2025-04-28T12:41:53.831577Z","shell.execute_reply.started":"2025-04-28T12:41:53.827801Z","shell.execute_reply":"2025-04-28T12:41:53.831008Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport scipy.io as sio\nfrom scipy.io import savemat\nimport numpy as np\nimport math\nimport random\nimport time\nfrom collections import OrderedDict\nimport matplotlib.pyplot as plt\nfrom itertools import cycle\nimport itertools as it\nfrom pathlib import Path\nimport os\n#import mysql.connector as mysql","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:42:26.514112Z","iopub.execute_input":"2025-04-28T12:42:26.514504Z","iopub.status.idle":"2025-04-28T12:42:26.519354Z","shell.execute_reply.started":"2025-04-28T12:42:26.514481Z","shell.execute_reply":"2025-04-28T12:42:26.518712Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom collections import OrderedDict\n\n\nclass ConvBN(nn.Sequential):\n    def __init__(self, in_planes, out_planes, kernel_size, groups=1):\n        if not isinstance(kernel_size, int):\n            padding = [(i - 1) // 2 for i in kernel_size]\n        else:\n            padding = (kernel_size - 1) // 2\n        super(ConvBN, self).__init__(OrderedDict([\n            ('conv', nn.Conv2d(in_planes, out_planes, kernel_size, padding=padding, groups=groups)),\n            ('bn', nn.BatchNorm2d(out_planes, eps=1e-03, momentum=0.99))\n        ]))\n\n\nclass RefineNet(nn.Module):\n    def __init__(self, img_channels=2):\n        super(RefineNet, self).__init__()\n\n        self.conv = nn.Sequential(OrderedDict([\n            (\"first_conv1x7\", ConvBN(img_channels, 8, [1, 7])),\n            (\"LeakyReLU_1\", nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n            (\"second_conv1x7\", ConvBN(8, 16, [1, 7])),\n            (\"LeakyReLU_2\", nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n            (\"third_conv1x7\", ConvBN(16, 2, [1, 7])),\n        ]))\n\n        self.conv_1 = nn.Sequential(OrderedDict([\n            (\"first_conv1x5\", ConvBN(img_channels, 8, [1, 5])),\n            (\"LeakyReLU_1\", nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n            (\"second_conv1x5\", ConvBN(8, 16, [1, 5])),\n            (\"LeakyReLU_2\", nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n            (\"third_conv1x5\", ConvBN(16, 2, [1, 5])),\n        ]))\n\n        self.conv1x1 = ConvBN(4, 2, [1, 7])\n        self.relu = nn.LeakyReLU(negative_slope=0.3, inplace=True)\n\n    def forward(self, x):\n        ori_x = x.clone()\n        x_1 = self.conv(x)\n        x_2 = self.conv_1(x)\n        x = torch.cat((x_1, x_2), dim=1)\n        x = self.relu(x)\n        x = self.conv1x1(x)\n        return self.relu(x + ori_x)\n\n\nclass Encoder_Compression(nn.Module):\n    def __init__(self):\n        super(Encoder_Compression, self).__init__()\n        self.conv = nn.Sequential(OrderedDict([\n            (\"conv1\", ConvBN(64, 32, [1, 7])),\n            (\"LeakyReLU_1\", nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n            (\"conv2\", ConvBN(32, 16, [1, 7])),\n            (\"LeakyReLU_2\", nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n            #(\"third_Conv1x7\",ConvBN(16,8,[1,7])),         for CR=8 \n        ]))\n\n        self.conv_2 = ConvBN(64, 16, [1, 7])\n        self.conv_3 = ConvBN(32, 16, [1, 7])\n        self.relu = nn.LeakyReLU(negative_slope=0.3, inplace=True)\n\n    def forward(self, x):\n        x_1 = self.conv(x)\n        x_2 = self.conv_2(x)\n        x = torch.cat((x_1, x_2), dim=1)\n        x = self.relu(x)\n        x = self.conv_3(x)\n        return self.relu(x)\n\n\nclass CLLWCsiNet(nn.Module):\n    def __init__(self, reduction=4, residual_num=2):\n        super(CLLWCsiNet, self).__init__()\n        self.encoder_p1 = nn.Sequential(OrderedDict([\n            (\"conv1x7\", ConvBN(2, 2, [1, 7])),\n            (\"LeakyReLU_1\", nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n            (\"conv7x1\", ConvBN(2, 2, [7, 1])),\n            (\"LeakyReLU_2\", nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n        ]))\n\n        self.encoder_p2 = nn.Sequential(OrderedDict([\n            ('conv1x5', ConvBN(2, 2, [1, 5])),\n            ('LeakyReLU_1', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n            ('conv5x1', ConvBN(2, 2, [5, 1])),\n        ]))\n\n        self.encoder_p3 = nn.Sequential(OrderedDict([\n            ('conv1x3', ConvBN(2, 2, [1, 3])),\n            ('LeakyReLU_1', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n            ('conv3x1', ConvBN(2, 2, [3, 1])),\n        ]))\n\n        self.con1x1 = ConvBN(6, 2, [1, 7])\n        self.relu = nn.LeakyReLU(negative_slope=0.3, inplace=True)\n\n        self.encoder_compression = Encoder_Compression()\n\n        self.decoder_get_feedback_in_UE = nn.Sequential(OrderedDict([\n            (\"conv1\", ConvBN(16, 32, [1, 7])),\n            (\"LeakyReLU_1\", nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n            (\"conv2\", ConvBN(32, 64, [1, 7])),\n            (\"LeakyReLU_2\", nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n        ]))\n\n        self.remove_AGN = nn.Sequential(OrderedDict([\n            (\"conv1\", ConvBN(16, 32, [1, 7])),\n            (\"LeakyReLU_1\", nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n            (\"conv2\", ConvBN(32, 64, [1, 7])),\n            (\"LeakyReLU_2\", nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n        ]))\n\n        self.decoder_refine_net = nn.ModuleList([RefineNet(2) for _ in range(residual_num)])\n\n        self._last_cov = nn.Sequential(OrderedDict([\n            (\"last_conv\", ConvBN(2, 2, [1, 7])),\n            (\"activation\", nn.Sigmoid())\n        ]))\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.xavier_uniform_(m.weight)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n    # def adding_noise(self, x):\n    #     signal_power = torch.mean(x**2)\n    #     SNR_dB = 40\n    #     SNR_linear = 10**(SNR_dB / 10)\n    #     noise_power = signal_power / SNR_linear\n    #     noise = torch.randn_like(x) * torch.sqrt(noise_power)\n    #    return x + noise\n\n    def forward(self, x):\n        batch_size = x.size(0)\n        x_1 = self.encoder_p1(x)\n        x_2 = self.encoder_p2(x)\n        x_3 = self.encoder_p3(x)\n        x = torch.cat((x_1, x_2, x_3), dim=1)\n        x = self.relu(self.con1x1(x))\n        x = x.view(batch_size, 64, 1, 32)\n\n        x = self.encoder_compression(x)\n        #x_noisy_feedback = self.adding_noise(x)\n        #y = self.remove_AGN(x_noisy_feedback)\n        x = self.decoder_get_feedback_in_UE(x)\n        #x = self.relu(x - y)\n        x = x.view(batch_size, 2, 32, 32)\n\n        for refine_layer in self.decoder_refine_net:\n            x = refine_layer(x)\n\n        return self._last_cov(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:45:20.038084Z","iopub.execute_input":"2025-04-28T12:45:20.038638Z","iopub.status.idle":"2025-04-28T12:45:20.056059Z","shell.execute_reply.started":"2025-04-28T12:45:20.038616Z","shell.execute_reply":"2025-04-28T12:45:20.055536Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"model = CLLWCsiNet()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:45:22.130395Z","iopub.execute_input":"2025-04-28T12:45:22.131037Z","iopub.status.idle":"2025-04-28T12:45:22.144841Z","shell.execute_reply.started":"2025-04-28T12:45:22.131006Z","shell.execute_reply":"2025-04-28T12:45:22.144105Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:45:25.152253Z","iopub.execute_input":"2025-04-28T12:45:25.152923Z","iopub.status.idle":"2025-04-28T12:45:25.156783Z","shell.execute_reply.started":"2025-04-28T12:45:25.152897Z","shell.execute_reply":"2025-04-28T12:45:25.156189Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"pytorch_total_params","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:45:27.166696Z","iopub.execute_input":"2025-04-28T12:45:27.167527Z","iopub.status.idle":"2025-04-28T12:45:27.171730Z","shell.execute_reply.started":"2025-04-28T12:45:27.167500Z","shell.execute_reply":"2025-04-28T12:45:27.171033Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"70268"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"import torch\n#from Trans_Net.utils import *\n\n\nstate_dict = torch.load(r'/kaggle/input/cllwcsinet-savemodels/CLLWCsiNet-Saved-models/cr-4/indoor/CLLWCsiNet_NoNoise_model_500_indoor_512_WithoutQuantization_pth',map_location=torch.device('cpu'))['model_state_dict']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:45:28.922029Z","iopub.execute_input":"2025-04-28T12:45:28.922624Z","iopub.status.idle":"2025-04-28T12:45:28.956651Z","shell.execute_reply.started":"2025-04-28T12:45:28.922593Z","shell.execute_reply":"2025-04-28T12:45:28.955841Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/1553781525.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state_dict = torch.load(r'/kaggle/input/cllwcsinet-savemodels/CLLWCsiNet-Saved-models/cr-4/indoor/CLLWCsiNet_NoNoise_model_500_indoor_512_WithoutQuantization_pth',map_location=torch.device('cpu'))['model_state_dict']\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"model.load_state_dict(state_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:45:31.249430Z","iopub.execute_input":"2025-04-28T12:45:31.249702Z","iopub.status.idle":"2025-04-28T12:45:31.259415Z","shell.execute_reply.started":"2025-04-28T12:45:31.249682Z","shell.execute_reply":"2025-04-28T12:45:31.258694Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"model.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:45:33.779095Z","iopub.execute_input":"2025-04-28T12:45:33.779380Z","iopub.status.idle":"2025-04-28T12:45:33.785781Z","shell.execute_reply.started":"2025-04-28T12:45:33.779360Z","shell.execute_reply":"2025-04-28T12:45:33.785212Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"CLLWCsiNet(\n  (encoder_p1): Sequential(\n    (conv1x7): ConvBN(\n      (conv): Conv2d(2, 2, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (LeakyReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n    (conv7x1): ConvBN(\n      (conv): Conv2d(2, 2, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0))\n      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (LeakyReLU_2): LeakyReLU(negative_slope=0.3, inplace=True)\n  )\n  (encoder_p2): Sequential(\n    (conv1x5): ConvBN(\n      (conv): Conv2d(2, 2, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (LeakyReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n    (conv5x1): ConvBN(\n      (conv): Conv2d(2, 2, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n  )\n  (encoder_p3): Sequential(\n    (conv1x3): ConvBN(\n      (conv): Conv2d(2, 2, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (LeakyReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n    (conv3x1): ConvBN(\n      (conv): Conv2d(2, 2, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n  )\n  (con1x1): ConvBN(\n    (conv): Conv2d(6, 2, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n    (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n  )\n  (relu): LeakyReLU(negative_slope=0.3, inplace=True)\n  (encoder_compression): Encoder_Compression(\n    (conv): Sequential(\n      (conv1): ConvBN(\n        (conv): Conv2d(64, 32, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n      )\n      (LeakyReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n      (conv2): ConvBN(\n        (conv): Conv2d(32, 16, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n        (bn): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n      )\n      (LeakyReLU_2): LeakyReLU(negative_slope=0.3, inplace=True)\n    )\n    (conv_2): ConvBN(\n      (conv): Conv2d(64, 16, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n      (bn): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (conv_3): ConvBN(\n      (conv): Conv2d(32, 16, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n      (bn): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (relu): LeakyReLU(negative_slope=0.3, inplace=True)\n  )\n  (decoder_get_feedback_in_UE): Sequential(\n    (conv1): ConvBN(\n      (conv): Conv2d(16, 32, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n      (bn): BatchNorm2d(32, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (LeakyReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n    (conv2): ConvBN(\n      (conv): Conv2d(32, 64, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (LeakyReLU_2): LeakyReLU(negative_slope=0.3, inplace=True)\n  )\n  (remove_AGN): Sequential(\n    (conv1): ConvBN(\n      (conv): Conv2d(16, 32, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n      (bn): BatchNorm2d(32, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (LeakyReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n    (conv2): ConvBN(\n      (conv): Conv2d(32, 64, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (LeakyReLU_2): LeakyReLU(negative_slope=0.3, inplace=True)\n  )\n  (decoder_refine_net): ModuleList(\n    (0-1): 2 x RefineNet(\n      (conv): Sequential(\n        (first_conv1x7): ConvBN(\n          (conv): Conv2d(2, 8, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n          (bn): BatchNorm2d(8, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n        )\n        (LeakyReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n        (second_conv1x7): ConvBN(\n          (conv): Conv2d(8, 16, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n          (bn): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n        )\n        (LeakyReLU_2): LeakyReLU(negative_slope=0.3, inplace=True)\n        (third_conv1x7): ConvBN(\n          (conv): Conv2d(16, 2, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n          (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n        )\n      )\n      (conv_1): Sequential(\n        (first_conv1x5): ConvBN(\n          (conv): Conv2d(2, 8, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n          (bn): BatchNorm2d(8, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n        )\n        (LeakyReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n        (second_conv1x5): ConvBN(\n          (conv): Conv2d(8, 16, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n          (bn): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n        )\n        (LeakyReLU_2): LeakyReLU(negative_slope=0.3, inplace=True)\n        (third_conv1x5): ConvBN(\n          (conv): Conv2d(16, 2, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n          (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n        )\n      )\n      (conv1x1): ConvBN(\n        (conv): Conv2d(4, 2, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n        (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n      )\n      (relu): LeakyReLU(negative_slope=0.3, inplace=True)\n    )\n  )\n  (_last_cov): Sequential(\n    (last_conv): ConvBN(\n      (conv): Conv2d(2, 2, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (activation): Sigmoid()\n  )\n)"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"model.qconfig = torch.quantization.get_default_qconfig('fbgemm')  # Set quantization config\nquantized_model = torch.quantization.quantize_dynamic(\n    model, {nn.Linear}, dtype=torch.qint8  # Adjust the module types as per your model\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:45:38.261823Z","iopub.execute_input":"2025-04-28T12:45:38.262331Z","iopub.status.idle":"2025-04-28T12:45:38.308167Z","shell.execute_reply.started":"2025-04-28T12:45:38.262306Z","shell.execute_reply":"2025-04-28T12:45:38.307429Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# For simplicity, I'm using a dummy input for calibration\ndummy_input = torch.randn(1, 2, 32, 32)  # Modify according to your input shape\nquantized_model(dummy_input)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:45:42.916824Z","iopub.execute_input":"2025-04-28T12:45:42.917098Z","iopub.status.idle":"2025-04-28T12:45:43.109015Z","shell.execute_reply.started":"2025-04-28T12:45:42.917079Z","shell.execute_reply":"2025-04-28T12:45:43.108440Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"tensor([[[[1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 8.6015e-03,\n           9.1594e-01, 6.5238e-01],\n          [9.1728e-01, 9.9892e-01, 4.7074e-04,  ..., 1.3163e-01,\n           6.8144e-01, 7.6978e-01],\n          [1.0000e+00, 9.9997e-01, 1.0000e+00,  ..., 3.6751e-02,\n           8.7335e-01, 4.1928e-01],\n          ...,\n          [1.0000e+00, 1.1364e-05, 6.3566e-01,  ..., 2.8783e-08,\n           9.9183e-01, 9.8027e-01],\n          [9.9841e-01, 9.9682e-01, 3.2049e-02,  ..., 1.1809e-05,\n           9.8508e-01, 2.9185e-01],\n          [1.0000e+00, 9.9980e-01, 9.9957e-01,  ..., 1.4717e-03,\n           9.9368e-01, 2.0414e-01]],\n\n         [[1.6770e-02, 9.1624e-01, 7.8061e-01,  ..., 9.7689e-01,\n           3.8514e-01, 8.7960e-01],\n          [8.8834e-01, 9.9677e-01, 4.4352e-05,  ..., 9.8468e-01,\n           6.2998e-01, 6.9593e-01],\n          [4.2592e-03, 9.9528e-01, 4.4093e-01,  ..., 9.9919e-01,\n           9.2032e-01, 7.2109e-01],\n          ...,\n          [9.9264e-01, 8.0115e-01, 9.8544e-03,  ..., 1.0000e+00,\n           9.9782e-01, 9.8887e-01],\n          [7.2554e-01, 9.9998e-01, 9.0146e-03,  ..., 9.9995e-01,\n           8.1730e-01, 9.6931e-01],\n          [1.3974e-01, 9.9304e-01, 1.0000e+00,  ..., 9.9989e-01,\n           1.8589e-01, 9.5064e-01]]]], grad_fn=<SigmoidBackward0>)"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"quantized_model.to('cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:45:46.296991Z","iopub.execute_input":"2025-04-28T12:45:46.297704Z","iopub.status.idle":"2025-04-28T12:45:46.308684Z","shell.execute_reply.started":"2025-04-28T12:45:46.297681Z","shell.execute_reply":"2025-04-28T12:45:46.307942Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"CLLWCsiNet(\n  (encoder_p1): Sequential(\n    (conv1x7): ConvBN(\n      (conv): Conv2d(2, 2, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (LeakyReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n    (conv7x1): ConvBN(\n      (conv): Conv2d(2, 2, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0))\n      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (LeakyReLU_2): LeakyReLU(negative_slope=0.3, inplace=True)\n  )\n  (encoder_p2): Sequential(\n    (conv1x5): ConvBN(\n      (conv): Conv2d(2, 2, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (LeakyReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n    (conv5x1): ConvBN(\n      (conv): Conv2d(2, 2, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n  )\n  (encoder_p3): Sequential(\n    (conv1x3): ConvBN(\n      (conv): Conv2d(2, 2, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (LeakyReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n    (conv3x1): ConvBN(\n      (conv): Conv2d(2, 2, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n  )\n  (con1x1): ConvBN(\n    (conv): Conv2d(6, 2, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n    (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n  )\n  (relu): LeakyReLU(negative_slope=0.3, inplace=True)\n  (encoder_compression): Encoder_Compression(\n    (conv): Sequential(\n      (conv1): ConvBN(\n        (conv): Conv2d(64, 32, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n      )\n      (LeakyReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n      (conv2): ConvBN(\n        (conv): Conv2d(32, 16, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n        (bn): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n      )\n      (LeakyReLU_2): LeakyReLU(negative_slope=0.3, inplace=True)\n    )\n    (conv_2): ConvBN(\n      (conv): Conv2d(64, 16, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n      (bn): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (conv_3): ConvBN(\n      (conv): Conv2d(32, 16, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n      (bn): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (relu): LeakyReLU(negative_slope=0.3, inplace=True)\n  )\n  (decoder_get_feedback_in_UE): Sequential(\n    (conv1): ConvBN(\n      (conv): Conv2d(16, 32, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n      (bn): BatchNorm2d(32, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (LeakyReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n    (conv2): ConvBN(\n      (conv): Conv2d(32, 64, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (LeakyReLU_2): LeakyReLU(negative_slope=0.3, inplace=True)\n  )\n  (remove_AGN): Sequential(\n    (conv1): ConvBN(\n      (conv): Conv2d(16, 32, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n      (bn): BatchNorm2d(32, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (LeakyReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n    (conv2): ConvBN(\n      (conv): Conv2d(32, 64, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (LeakyReLU_2): LeakyReLU(negative_slope=0.3, inplace=True)\n  )\n  (decoder_refine_net): ModuleList(\n    (0-1): 2 x RefineNet(\n      (conv): Sequential(\n        (first_conv1x7): ConvBN(\n          (conv): Conv2d(2, 8, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n          (bn): BatchNorm2d(8, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n        )\n        (LeakyReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n        (second_conv1x7): ConvBN(\n          (conv): Conv2d(8, 16, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n          (bn): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n        )\n        (LeakyReLU_2): LeakyReLU(negative_slope=0.3, inplace=True)\n        (third_conv1x7): ConvBN(\n          (conv): Conv2d(16, 2, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n          (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n        )\n      )\n      (conv_1): Sequential(\n        (first_conv1x5): ConvBN(\n          (conv): Conv2d(2, 8, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n          (bn): BatchNorm2d(8, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n        )\n        (LeakyReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n        (second_conv1x5): ConvBN(\n          (conv): Conv2d(8, 16, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n          (bn): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n        )\n        (LeakyReLU_2): LeakyReLU(negative_slope=0.3, inplace=True)\n        (third_conv1x5): ConvBN(\n          (conv): Conv2d(16, 2, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n          (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n        )\n      )\n      (conv1x1): ConvBN(\n        (conv): Conv2d(4, 2, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n        (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n      )\n      (relu): LeakyReLU(negative_slope=0.3, inplace=True)\n    )\n  )\n  (_last_cov): Sequential(\n    (last_conv): ConvBN(\n      (conv): Conv2d(2, 2, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (activation): Sigmoid()\n  )\n)"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"criterion = nn.MSELoss().to('cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:45:51.150952Z","iopub.execute_input":"2025-04-28T12:45:51.151247Z","iopub.status.idle":"2025-04-28T12:45:51.155194Z","shell.execute_reply.started":"2025-04-28T12:45:51.151225Z","shell.execute_reply":"2025-04-28T12:45:51.154421Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"envir = 'indoor'  # 'indoor' or 'outdoor'\n# image params\nimg_height = 32\nimg_width = 32\nimg_channels = 2\nimg_total = img_height * img_width * img_channels\n# network params\n#residual_num = 2\nencoded_dim = 512  # compress rate=1/4->dim.=512, compress rate=1/16->dim.=128, compress rate=1/32->dim.=64, compress rate=1/64->dim.=32","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:45:53.262292Z","iopub.execute_input":"2025-04-28T12:45:53.262604Z","iopub.status.idle":"2025-04-28T12:45:53.267058Z","shell.execute_reply.started":"2025-04-28T12:45:53.262585Z","shell.execute_reply":"2025-04-28T12:45:53.266484Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# envir = 'indoor'  # 'indoor' or 'outdoor'\n# # image params\n# img_height = 32\n# img_width = 32\n# img_channels = 2\n# img_total = img_height * img_width * img_channels\n# # network params\n# residual_num = 2\n\n# encoded_dim = 512  # compress rate=1/4->dim.=512, compress rate=1/16->dim.=128, compress rate=1/32->dim.=64, compress rate=1/64->dim.=32\n# Data loading\nif envir == 'indoor':\n    mat = sio.loadmat(r'/kaggle/input/cost2100/DATA_Htrainin.mat')\n    x_train = mat['HT']  # array\n    mat = sio.loadmat(r'/kaggle/input/cost2100/DATA_Hvalin.mat')\n    x_val = mat['HT']  # array\n    mat = sio.loadmat(r'/kaggle/input/cost2100/DATA_Htestin.mat')\n    x_test = mat['HT']  # array\n    mat = sio.loadmat(r'/kaggle/input/cost2100/DATA_HtestFin_all.mat')\n    X_test = mat['HF_all']  # array\n\nelif envir == 'outdoor':\n    mat = sio.loadmat(r'/kaggle/input/cost2100/DATA_Htrainout.mat')\n    x_train = mat['HT']  # array\n    mat = sio.loadmat(r'/kaggle/input/cost2100/DATA_Hvalout.mat')\n    x_val = mat['HT']  # array\n    mat = sio.loadmat(r'/kaggle/input/cost2100/DATA_Htestout.mat')\n    x_test = mat['HT']  # array\n    mat = sio.loadmat(r'/kaggle/input/cost2100/DATA_HtestFout_all.mat')\n    X_test = mat['HF_all']  # array","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:46:58.808243Z","iopub.execute_input":"2025-04-28T12:46:58.809010Z","iopub.status.idle":"2025-04-28T12:47:47.512048Z","shell.execute_reply.started":"2025-04-28T12:46:58.808986Z","shell.execute_reply":"2025-04-28T12:47:47.511283Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"import numpy as np\n\nx_train = x_train.astype('float32')\nx_val = x_val.astype('float32')\nx_test = x_test.astype('float32')\n\nx_train_length = len(x_train)\nx_val_length = len(x_val)\nx_test_length = len(x_test)\n\nx_train = np.reshape(x_train, (x_train_length, img_channels, img_height, img_width))  # adapt this if using `channels_first` image data format\nx_val = np.reshape(x_val, (x_val_length, img_channels, img_height, img_width))  # adapt this if using `channels_first` image data format\nx_test = np.reshape(x_test, (x_test_length, img_channels, img_height, img_width))  # adapt this if using `channels_first` image data format\n\nx_train = torch.tensor(x_train)\nx_val = torch.tensor(x_val)\nx_test = torch.tensor(x_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:47:52.749931Z","iopub.execute_input":"2025-04-28T12:47:52.750209Z","iopub.status.idle":"2025-04-28T12:47:53.943835Z","shell.execute_reply.started":"2025-04-28T12:47:52.750187Z","shell.execute_reply":"2025-04-28T12:47:53.943218Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"x_test.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:47:56.747665Z","iopub.execute_input":"2025-04-28T12:47:56.748367Z","iopub.status.idle":"2025-04-28T12:47:56.753724Z","shell.execute_reply.started":"2025-04-28T12:47:56.748332Z","shell.execute_reply":"2025-04-28T12:47:56.753053Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"torch.Size([20000, 2, 32, 32])"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"img_height = 32\nimg_width = 32\nimg_channels = 2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:47:58.831341Z","iopub.execute_input":"2025-04-28T12:47:58.831946Z","iopub.status.idle":"2025-04-28T12:47:58.835677Z","shell.execute_reply.started":"2025-04-28T12:47:58.831915Z","shell.execute_reply":"2025-04-28T12:47:58.834910Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import math\nwith torch.no_grad():\n\n    #torch.cuda.empty_cache()\n    quantized_model.eval()\n    device='cpu'\n    x_hat = quantized_model(x_test)\n    #torch.quantization.convert(quantized_model, inplace=True)\n    x_test = x_test.to('cpu')\n    x_hat=x_hat.to('cpu')\n\n    # Calcaulating the NMSE and rho\n    # if envir == 'indoor':\n    #     mat = sio.loadmat('D:\\Cost2100\\DATA_HtestFin_all.mat')\n    #     X_test = mat['HF_all']  # array\n\n    # elif envir == 'outdoor':\n    #     mat = sio.loadmat('D:\\Cost2100\\DATA_HtestFout_all.mat')\n    #     X_test = mat['HF_all']  # array\n\n    #X_test = torch.tensor(X_test)\n    #X_test = torch.reshape(X_test, (len(X_test), img_height, 125))\n    x_test_real = torch.reshape(x_test[:, 0, :, :], (len(x_test), -1))\n    x_test_imag = torch.reshape(x_test[:, 1, :, :], (len(x_test), -1))\n    x_test_C = x_test_real - 0.5 + 1j * (x_test_imag - 0.5)\n    x_hat_real = torch.reshape(x_hat[:, 0, :, :], (len(x_hat), -1))\n    x_hat_imag = torch.reshape(x_hat[:, 1, :, :], (len(x_hat), -1))\n    x_hat_C = x_hat_real - 0.5 + 1j * (x_hat_imag - 0.5)\n    x_hat_F = torch.reshape(x_hat_C, (len(x_hat_C), img_height, img_width))\n    X_hat = torch.fft.fft(torch.cat((x_hat_F, torch.zeros((len(x_hat_C), img_height, 257 - img_width))), axis=2), axis=2)\n    X_hat = X_hat[:, :, 0:125]\n\n    #n1 = torch.sqrt(torch.sum(torch.conj(X_test) * X_test, axis=1))\n    #n2 = torch.sqrt(torch.sum(torch.conj(X_hat) * X_hat, axis=1))\n    #aa = abs(torch.sum(torch.conj(X_test) * X_hat, axis=1))\n    #rho = torch.mean(aa / (n1 * n2), axis=1)\n    X_hat = torch.reshape(X_hat, (len(X_hat), -1))\n    #X_test = torch.reshape(X_test, (len(X_test), -1))\n    power = torch.sum(abs(x_test_C) ** 2, axis=1)\n    power_d = torch.sum(abs(X_hat) ** 2, axis=1)\n    mse = torch.sum(abs(x_test_C - x_hat_C) ** 2, axis=1)\n    NMSE = 10 * math.log10(torch.mean(mse / power))\n    #Correlation = torch.mean(rho).item().real\n\n    # print(\"In \" + envir + \" environment\")\n    # print(\"When dimension is\", encoded_dim)\n    print(\"NMSE is \", NMSE)\n    #print(\"Correlation is \", Correlation)\n#\n# file = 'CsiNet_' + (envir) + '_dim' + str(encoded_dim) + time.strftime('_%m_%d_%H_%M')\n# outfile = \"result/result_%s.mat\" % file\n# savemat(outfile, {'train_loss_history': train_loss_history,\n#                   'val_loss_history': val_loss_history,\n#                   'training_time': training_time,\n#                   'NMSE': NMSE,\n#                   'Correlation': Correlation})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:48:02.018107Z","iopub.execute_input":"2025-04-28T12:48:02.018704Z","iopub.status.idle":"2025-04-28T12:48:43.247627Z","shell.execute_reply.started":"2025-04-28T12:48:02.018681Z","shell.execute_reply":"2025-04-28T12:48:43.246979Z"}},"outputs":[{"name":"stdout","text":"NMSE is  -14.422470030227604\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"# ====== COMPREHENSIVE QUANTIZED MODEL BENCHMARK ======\nimport time\nimport torch\nfrom tabulate import tabulate\n\ndef benchmark_model(model, input_shape=(2, 32, 32), warmup=10, repetitions=100, batch_sizes=[1, 8, 16, 32, 64], quantized=False):\n    \"\"\"Run comprehensive benchmarks for both quantized and regular models\"\"\"\n    results = []\n    model.eval()\n    \n    # Prepare model\n    if quantized:\n        model = torch.quantization.quantize_dynamic(\n            model, \n            {torch.nn.Conv2d, torch.nn.Linear},  # Quantize Conv2d layers too\n            dtype=torch.qint8\n        )\n        model_type = \"Quantized\"\n    else:\n        model_type = \"FP32\"\n    \n    # Benchmark for CPU and GPU (if available and not quantized)\n    devices = ['cpu']\n    if torch.cuda.is_available() and not quantized:\n        devices.append('cuda')\n    \n    for device in devices:\n        # Move model to device\n        model.to(device)\n        \n        # Single sample benchmark\n        dummy_input = torch.randn(1, *input_shape).to(device)\n        \n        # Warm-up\n        with torch.no_grad():\n            for _ in range(warmup):\n                _ = model(dummy_input)\n            if device == 'cuda':\n                torch.cuda.synchronize()\n        \n        # Measurement\n        start_time = time.time()\n        with torch.no_grad():\n            for _ in range(repetitions):\n                _ = model(dummy_input)\n                if device == 'cuda':\n                    torch.cuda.synchronize()\n        avg_time = (time.time() - start_time) * 1000 / repetitions\n        \n        results.append([\n            f\"{device.upper()} ({model_type})\",\n            \"Single\",\n            f\"{avg_time:.2f} ms\",\n            f\"{1000/avg_time:.2f} samples/sec\"\n        ])\n        \n        # Batch processing benchmark\n        for bs in batch_sizes:\n            dummy_batch = torch.randn(bs, *input_shape).to(device)\n            \n            # Warm-up\n            with torch.no_grad():\n                _ = model(dummy_batch)\n                if device == 'cuda':\n                    torch.cuda.synchronize()\n            \n            # Measure\n            start = time.time()\n            with torch.no_grad():\n                _ = model(dummy_batch)\n                if device == 'cuda':\n                    torch.cuda.synchronize()\n            \n            total_time = (time.time() - start) * 1000\n            time_per_sample = total_time / bs\n            \n            results.append([\n                f\"{device.upper()} ({model_type})\",\n                f\"Batch {bs}\",\n                f\"{total_time:.2f} ms\",\n                f\"{1000/time_per_sample:.2f} samples/sec\"\n            ])\n    \n    return results\n\n# Run benchmarks\nprint(\"\\n=== Model Benchmark Results ===\")\nbenchmark_results = benchmark_model(model, quantized=False)\nquantized_results = benchmark_model(model, quantized=True)\n\n# Combine and print results\nall_results = benchmark_results + quantized_results\nheaders = [\"Configuration\", \"Test Type\", \"Inference Time\", \"Throughput\"]\nprint(tabulate(all_results, headers=headers))\n\n# Additional metrics\nprint(\"\\n=== Quantization Benefits ===\")\n# Find matching CPU results to compare\nfp32_cpu_single = next(r for r in benchmark_results if \"CPU (FP32)\" in r[0] and \"Single\" in r[1])\nquant_cpu_single = next(r for r in quantized_results if \"CPU (Quantized)\" in r[0] and \"Single\" in r[1])\n\nspeedup = float(fp32_cpu_single[2].split()[0]) / float(quant_cpu_single[2].split()[0])\nprint(f\"Quantization speedup (CPU single sample): {speedup:.2f}x\")\n\n# Model size comparison\ndef get_model_size(model):\n    torch.save(model.state_dict(), \"temp.p\")\n    size = os.path.getsize(\"temp.p\")/1e6  # in MB\n    os.remove(\"temp.p\")\n    return size\n\nfp32_size = get_model_size(model)\nquantized_model = torch.quantization.quantize_dynamic(model, {torch.nn.Conv2d}, dtype=torch.qint8)\nquant_size = get_model_size(quantized_model)\n\nprint(f\"\\nModel size reduction: {fp32_size:.2f}MB -> {quant_size:.2f}MB ({fp32_size/quant_size:.1f}x smaller)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T13:00:24.740402Z","iopub.execute_input":"2025-04-28T13:00:24.740745Z","iopub.status.idle":"2025-04-28T13:00:26.315535Z","shell.execute_reply.started":"2025-04-28T13:00:24.740717Z","shell.execute_reply":"2025-04-28T13:00:26.314919Z"}},"outputs":[{"name":"stdout","text":"\n=== Model Benchmark Results ===\nConfiguration    Test Type    Inference Time    Throughput\n---------------  -----------  ----------------  --------------------\nCPU (FP32)       Single       2.92 ms           342.03 samples/sec\nCPU (FP32)       Batch 1      2.99 ms           334.39 samples/sec\nCPU (FP32)       Batch 8      8.78 ms           911.04 samples/sec\nCPU (FP32)       Batch 16     11.16 ms          1433.95 samples/sec\nCPU (FP32)       Batch 32     17.08 ms          1873.50 samples/sec\nCPU (FP32)       Batch 64     43.58 ms          1468.58 samples/sec\nCUDA (FP32)      Single       3.27 ms           305.45 samples/sec\nCUDA (FP32)      Batch 1      3.25 ms           308.16 samples/sec\nCUDA (FP32)      Batch 8      3.43 ms           2335.20 samples/sec\nCUDA (FP32)      Batch 16     3.32 ms           4814.47 samples/sec\nCUDA (FP32)      Batch 32     3.31 ms           9674.05 samples/sec\nCUDA (FP32)      Batch 64     3.90 ms           16407.03 samples/sec\nCPU (Quantized)  Single       3.26 ms           306.89 samples/sec\nCPU (Quantized)  Batch 1      3.09 ms           323.14 samples/sec\nCPU (Quantized)  Batch 8      9.22 ms           867.33 samples/sec\nCPU (Quantized)  Batch 16     12.62 ms          1268.00 samples/sec\nCPU (Quantized)  Batch 32     18.26 ms          1752.88 samples/sec\nCPU (Quantized)  Batch 64     50.09 ms          1277.58 samples/sec\n\n=== Quantization Benefits ===\nQuantization speedup (CPU single sample): 0.90x\n\nModel size reduction: 0.35MB -> 0.35MB (1.0x smaller)\n","output_type":"stream"}],"execution_count":35}]}