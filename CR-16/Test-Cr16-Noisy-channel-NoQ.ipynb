{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T18:16:29.782323Z",
     "iopub.status.busy": "2025-04-27T18:16:29.781584Z",
     "iopub.status.idle": "2025-04-27T18:16:30.168639Z",
     "shell.execute_reply": "2025-04-27T18:16:30.167896Z",
     "shell.execute_reply.started": "2025-04-27T18:16:29.782283Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/cost2100/DATA_Hvalout.mat\n",
      "/kaggle/input/cost2100/DATA_Htrainin.mat\n",
      "/kaggle/input/cost2100/DATA_HtestFout_all.mat\n",
      "/kaggle/input/cost2100/DATA_Htestout.mat\n",
      "/kaggle/input/cost2100/DATA_Htestin.mat\n",
      "/kaggle/input/cost2100/DATA_Hvalin.mat\n",
      "/kaggle/input/cost2100/DATA_Htrainout.mat\n",
      "/kaggle/input/cost2100/DATA_HtestFin_all.mat\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input/cost2100'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T18:16:34.039571Z",
     "iopub.status.busy": "2025-04-27T18:16:34.038793Z",
     "iopub.status.idle": "2025-04-27T18:16:36.160075Z",
     "shell.execute_reply": "2025-04-27T18:16:36.159405Z",
     "shell.execute_reply.started": "2025-04-27T18:16:34.039543Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import sys\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import traceback\n",
    "import scipy.io as sio\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T18:16:43.433447Z",
     "iopub.status.busy": "2025-04-27T18:16:43.432981Z",
     "iopub.status.idle": "2025-04-27T18:16:43.455808Z",
     "shell.execute_reply": "2025-04-27T18:16:43.455033Z",
     "shell.execute_reply.started": "2025-04-27T18:16:43.433423Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ConvBN(nn.Sequential):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size,groups=1):\n",
    "        if not isinstance(kernel_size, int):\n",
    "            padding = [(i - 1) // 2 for i in kernel_size]\n",
    "        else:\n",
    "            padding = (kernel_size - 1) // 2\n",
    "        super(ConvBN, self).__init__(OrderedDict([\n",
    "            ('conv', nn.Conv2d(in_planes, out_planes, kernel_size,\n",
    "                               padding=padding)),\n",
    "            ('bn', nn.BatchNorm2d(out_planes,eps=1e-03, momentum=0.99))\n",
    "        ]))\n",
    "\n",
    "        \n",
    "\n",
    "class RefineNet(nn.Module):\n",
    "    def __init__(self, img_channels=2):\n",
    "        super(RefineNet, self).__init__()\n",
    "        self.conv=nn.Sequential(OrderedDict([\n",
    "            (\"first_conv1x7\",ConvBN(img_channels,8,[1,7])),\n",
    "            (\"PReLU_1\",nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "            (\"second_Conv1x7\",ConvBN(8,16,[1,7])),\n",
    "            (\"PReLU_2\",nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "            (\"third_Conv1x7\",ConvBN(16,2,[1,7])),    \n",
    "        ]))\n",
    "        \n",
    "        self.conv_1=nn.Sequential(OrderedDict([\n",
    "            (\"first_conv1x7\",ConvBN(img_channels,8,[1,5])),\n",
    "            (\"PReLU_1\",nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "            (\"second_Conv1x7\",ConvBN(8,16,[1,5])),\n",
    "            (\"PReLU_2\",nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "            (\"third_Conv1x7\",ConvBN(16,2, [1,5])),    \n",
    "        ]))\n",
    "        \n",
    "        self.conv1x1 = ConvBN(4, 2, [1,7])\n",
    "        self.Relu = nn.LeakyReLU(negative_slope=0.3, inplace=True)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        ori_x = x.clone()\n",
    "\n",
    "        # concatenate\n",
    "        x_1 = self.conv(x)\n",
    "        x_2 = self.conv_1(x)\n",
    "        x = torch.cat((x_1, x_2), dim=1)\n",
    "        x = self.Relu(x)\n",
    "        x =self.conv1x1(x)\n",
    "\n",
    "        return self.Relu(x + ori_x)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class Encoder_Compression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder_Compression, self).__init__()\n",
    "        self.conv=nn.Sequential(OrderedDict([\n",
    "            (\"first_conv1x7\",ConvBN(64,32,[1,7])),\n",
    "            (\"PReLU_1\",nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "            (\"second_Conv1x7\",ConvBN(32,16,[1,7])),\n",
    "            (\"PReLU_2\",nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "            (\"third_Conv1x7\",ConvBN(16,4,[1,7])),\n",
    "        ]))\n",
    "        \n",
    "        self.conv_2=ConvBN(64,4,[1,7])\n",
    "        self.conv_3=ConvBN(8,4,[1,7])\n",
    "        \n",
    "        \n",
    "        self.LeakyRelu = nn.LeakyReLU(negative_slope=0.3, inplace=True)\n",
    "               \n",
    "    def forward(self, x):        \n",
    "        # concatenate\n",
    "        x_1= self.conv(x)\n",
    "        x_2= self.conv_2(x)\n",
    "        x = torch.cat((x_1, x_2), dim=1)\n",
    "        x = self.LeakyRelu(x)\n",
    "        x = self.conv_3(x)\n",
    "        #print(\"finish\")\n",
    "        ###### Send Feedback From User Equipement\" \n",
    "        return self.LeakyRelu(x)\n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    " \n",
    "    \n",
    "    \n",
    "\n",
    "class CLLWCsiNet(nn.Module):\n",
    "    def __init__(self,reduction=4,residual_num=2):\n",
    "        super(CLLWCsiNet, self).__init__()\n",
    "        total_size, in_channel, w, h = 2048, 2, 32, 32\n",
    "        \n",
    "        self.encoder_p1 = nn.Sequential(OrderedDict([\n",
    "            (\"first_conv1x7\",ConvBN(2,2, [1,7])),\n",
    "            (\"LeakyReLU_1\",nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "            (\"second_conv1x7\",ConvBN(2,2,[7,1])),\n",
    "            #(\"LeakyReLU_2\",nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "            ]))\n",
    "        \n",
    "        self.encoder_p2= nn.Sequential(OrderedDict([\n",
    "            ('conv1x3', ConvBN(2, 2, [1, 5])),\n",
    "            ('LeakyRelu_1', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "            ('conv3x1', ConvBN(2, 2, [5, 1])),\n",
    "            ]))\n",
    "        \n",
    "        self.encoder_p3= nn.Sequential(OrderedDict([\n",
    "            ('conv1x3', ConvBN(2, 2, [1, 3])),\n",
    "            ('LeakyRelu_1', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "            ('conv3x1', ConvBN(2, 2, [3, 1])),\n",
    "            ]))\n",
    "        \n",
    "        self.con1x1=ConvBN(6, 2, [1,7])\n",
    "        self.LeakyReLU=nn.LeakyReLU(negative_slope=0.3, inplace=True)\n",
    "        \n",
    "        ######################## CNN base Laten Space ########################################\n",
    "        self.encoder_compression=Encoder_Compression()\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.decoder_get_feedback_in_UE=nn.Sequential(OrderedDict([\n",
    "            (\"first_conv1x7\",ConvBN(4,8,[1,7])),\n",
    "            (\"LeakyRelu_1\",nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "            (\"conv1x7\",ConvBN(8,16,[1,7])),\n",
    "            (\"LeakyRelu_2\",nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "            (\"second_conv1x7\",ConvBN(16,64,[1,7])),\n",
    "             #(\"LeakyRelu_3\",nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "            ]))\n",
    "        \n",
    "        \n",
    "        self.remove_AGN=nn.Sequential(OrderedDict([\n",
    "            (\"conv_1x7\",ConvBN(4,8,[1,7])),\n",
    "            (\"LeakyReLu_1\",nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "            (\"conv_7x1\",ConvBN(8,16,[1,7])),\n",
    "            (\"LeakyReLu_1\",nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n",
    "            (\"conv_3x3\",ConvBN(16,64,[1,7])),\n",
    "        ]))\n",
    "        \n",
    "        \n",
    "        ###################################    refine Module #########################################\n",
    "#         self.refine =  nn.Sequential(OrderedDict([\n",
    "#             (\"MultiResolutionRefineBlock\", MultiResolutionRefineBlock()),\n",
    "#             (\"MultiResolutionRefineBlock\", MultiResolutionRefineBlock())\n",
    "#         ]))\n",
    "        \n",
    "        \n",
    "        self.decoder_refine_net = nn.ModuleList([RefineNet(in_channel) for _ in range(residual_num)])\n",
    "        \n",
    "        self._last_cov=nn.Sequential(OrderedDict([\n",
    "            (\"firstcov2\",ConvBN(2,2,[1,7])),\n",
    "            (\"activation\",nn.Sigmoid())\n",
    "        ]))\n",
    "        \n",
    "        \n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv2d)):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "        \n",
    "    def adding_noise(self, x):\n",
    "        # Ensure input is normalized to [0, 1]\n",
    "        #assert x.min() >= 0 and x.max() <= 1, \"Input must be in [0, 1] range. Normalize first!\"\n",
    "        \n",
    "        # Compute signal power (assumes [0,1] range)\n",
    "        signal_power = torch.mean(x**2)\n",
    "        \n",
    "        # Set SNR (e.g., 20 dB)\n",
    "        snr_db = -10 \n",
    "        snr_linear = 10 ** (snr_db / 10)\n",
    "        \n",
    "        # Calculate noise power\n",
    "        noise_power = signal_power / snr_linear\n",
    "        \n",
    "        # Generate noise\n",
    "        noise = torch.randn_like(x) * torch.sqrt(noise_power)\n",
    "        \n",
    "        # Add noise and clip to maintain [0,1] range\n",
    "        noisy_x = torch.clamp(x + noise, 0, 1)\n",
    "        \n",
    "        return noisy_x\n",
    "    \n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, channels, height, width = x.size()\n",
    "        #print(x.size())\n",
    "        x_1=self.encoder_p1(x)\n",
    "        x_2=self.encoder_p2(x)\n",
    "        x_3=self.encoder_p3(x)\n",
    "        x=torch.cat((x_1,x_2,x_3),dim=1)\n",
    "        x=self.con1x1(x)\n",
    "        x=self.LeakyReLU(x)\n",
    "        #print(x.size())\n",
    "        x = x.contiguous().view(batch_size,64 ,1,32)\n",
    "        #print(x.size())\n",
    "        x=self.encoder_compression(x)\n",
    "        x_noisy_feedback=self.adding_noise(x)\n",
    "        y=self.remove_AGN(x_noisy_feedback)\n",
    "        x=self.decoder_get_feedback_in_UE(x)\n",
    "        x=x-y\n",
    "        x=self.LeakyReLU(x)\n",
    "        x = x.contiguous().view(batch_size,2 ,32,32)\n",
    "        #x = self.refine(x)\n",
    "        for layer in self.decoder_refine_net:\n",
    "            x = layer(x)\n",
    "        x=self._last_cov(x)\n",
    "       \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T18:16:48.283147Z",
     "iopub.status.busy": "2025-04-27T18:16:48.282786Z",
     "iopub.status.idle": "2025-04-27T18:16:48.305790Z",
     "shell.execute_reply": "2025-04-27T18:16:48.304850Z",
     "shell.execute_reply.started": "2025-04-27T18:16:48.283122Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = CLLWCsiNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T18:16:51.409633Z",
     "iopub.status.busy": "2025-04-27T18:16:51.408813Z",
     "iopub.status.idle": "2025-04-27T18:16:51.414151Z",
     "shell.execute_reply": "2025-04-27T18:16:51.413320Z",
     "shell.execute_reply.started": "2025-04-27T18:16:51.409604Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T18:16:53.866330Z",
     "iopub.status.busy": "2025-04-27T18:16:53.865935Z",
     "iopub.status.idle": "2025-04-27T18:16:53.873557Z",
     "shell.execute_reply": "2025-04-27T18:16:53.872650Z",
     "shell.execute_reply.started": "2025-04-27T18:16:53.866305Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70268"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T18:17:37.559920Z",
     "iopub.status.busy": "2025-04-27T18:17:37.559571Z",
     "iopub.status.idle": "2025-04-27T18:17:37.613585Z",
     "shell.execute_reply": "2025-04-27T18:17:37.612731Z",
     "shell.execute_reply.started": "2025-04-27T18:17:37.559895Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_91/1243910273.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(r'/kaggle/input/cllwcsinet-savemodels/CLLWCsiNet-Saved-models/cr-4/outdoor/CLLWCsiNet_model_500_outdoor_512.pth',map_location=torch.device('cpu'))['model_state_dict']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#from Trans_Net.utils import *\n",
    "\n",
    "\n",
    "state_dict = torch.load(r'/kaggle/input/cllwcsinet-savemodels/CLLWCsiNet-Saved-models/cr-4/outdoor/CLLWCsiNet_model_500_outdoor_512.pth',map_location=torch.device('cpu'))['model_state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T18:17:43.200779Z",
     "iopub.status.busy": "2025-04-27T18:17:43.200422Z",
     "iopub.status.idle": "2025-04-27T18:17:43.211442Z",
     "shell.execute_reply": "2025-04-27T18:17:43.210634Z",
     "shell.execute_reply.started": "2025-04-27T18:17:43.200752Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T18:17:50.435211Z",
     "iopub.status.busy": "2025-04-27T18:17:50.434623Z",
     "iopub.status.idle": "2025-04-27T18:17:50.441851Z",
     "shell.execute_reply": "2025-04-27T18:17:50.441227Z",
     "shell.execute_reply.started": "2025-04-27T18:17:50.435175Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLLWCsiNet(\n",
       "  (encoder_p1): Sequential(\n",
       "    (conv1x7): ConvBN(\n",
       "      (conv): Conv2d(2, 2, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n",
       "      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (LeakyReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "    (conv7x1): ConvBN(\n",
       "      (conv): Conv2d(2, 2, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0))\n",
       "      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (LeakyReLU_2): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "  )\n",
       "  (encoder_p2): Sequential(\n",
       "    (conv1x5): ConvBN(\n",
       "      (conv): Conv2d(2, 2, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
       "      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (LeakyReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "    (conv5x1): ConvBN(\n",
       "      (conv): Conv2d(2, 2, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n",
       "      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (encoder_p3): Sequential(\n",
       "    (conv1x3): ConvBN(\n",
       "      (conv): Conv2d(2, 2, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (LeakyReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "    (conv3x1): ConvBN(\n",
       "      (conv): Conv2d(2, 2, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (con1x1): ConvBN(\n",
       "    (conv): Conv2d(6, 2, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n",
       "    (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (relu): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "  (encoder_compression): Encoder_Compression(\n",
       "    (conv): Sequential(\n",
       "      (conv1): ConvBN(\n",
       "        (conv): Conv2d(64, 32, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (LeakyReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "      (conv2): ConvBN(\n",
       "        (conv): Conv2d(32, 16, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (LeakyReLU_2): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "    )\n",
       "    (conv_2): ConvBN(\n",
       "      (conv): Conv2d(64, 16, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n",
       "      (bn): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_3): ConvBN(\n",
       "      (conv): Conv2d(32, 16, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n",
       "      (bn): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (relu): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "  )\n",
       "  (decoder_get_feedback_in_UE): Sequential(\n",
       "    (conv1): ConvBN(\n",
       "      (conv): Conv2d(16, 32, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (LeakyReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "    (conv2): ConvBN(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (LeakyReLU_2): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "  )\n",
       "  (remove_AGN): Sequential(\n",
       "    (conv1): ConvBN(\n",
       "      (conv): Conv2d(16, 32, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (LeakyReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "    (conv2): ConvBN(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (LeakyReLU_2): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "  )\n",
       "  (decoder_refine_net): ModuleList(\n",
       "    (0-1): 2 x RefineNet(\n",
       "      (conv): Sequential(\n",
       "        (first_conv1x7): ConvBN(\n",
       "          (conv): Conv2d(2, 8, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n",
       "          (bn): BatchNorm2d(8, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (LeakyReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "        (second_conv1x7): ConvBN(\n",
       "          (conv): Conv2d(8, 16, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n",
       "          (bn): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (LeakyReLU_2): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "        (third_conv1x7): ConvBN(\n",
       "          (conv): Conv2d(16, 2, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n",
       "          (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (conv_1): Sequential(\n",
       "        (first_conv1x5): ConvBN(\n",
       "          (conv): Conv2d(2, 8, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
       "          (bn): BatchNorm2d(8, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (LeakyReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "        (second_conv1x5): ConvBN(\n",
       "          (conv): Conv2d(8, 16, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
       "          (bn): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (LeakyReLU_2): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "        (third_conv1x5): ConvBN(\n",
       "          (conv): Conv2d(16, 2, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
       "          (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (conv1x1): ConvBN(\n",
       "        (conv): Conv2d(4, 2, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n",
       "        (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (_last_cov): Sequential(\n",
       "    (last_conv): ConvBN(\n",
       "      (conv): Conv2d(2, 2, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n",
       "      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (activation): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T18:18:00.778156Z",
     "iopub.status.busy": "2025-04-27T18:18:00.777708Z",
     "iopub.status.idle": "2025-04-27T18:18:00.787751Z",
     "shell.execute_reply": "2025-04-27T18:18:00.786834Z",
     "shell.execute_reply.started": "2025-04-27T18:18:00.778133Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLLWCsiNet(\n",
       "  (encoder_p1): Sequential(\n",
       "    (conv1x7): ConvBN(\n",
       "      (conv): Conv2d(2, 2, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n",
       "      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (LeakyReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "    (conv7x1): ConvBN(\n",
       "      (conv): Conv2d(2, 2, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0))\n",
       "      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (LeakyReLU_2): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "  )\n",
       "  (encoder_p2): Sequential(\n",
       "    (conv1x5): ConvBN(\n",
       "      (conv): Conv2d(2, 2, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
       "      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (LeakyReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "    (conv5x1): ConvBN(\n",
       "      (conv): Conv2d(2, 2, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n",
       "      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (encoder_p3): Sequential(\n",
       "    (conv1x3): ConvBN(\n",
       "      (conv): Conv2d(2, 2, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (LeakyReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "    (conv3x1): ConvBN(\n",
       "      (conv): Conv2d(2, 2, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (con1x1): ConvBN(\n",
       "    (conv): Conv2d(6, 2, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n",
       "    (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (relu): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "  (encoder_compression): Encoder_Compression(\n",
       "    (conv): Sequential(\n",
       "      (conv1): ConvBN(\n",
       "        (conv): Conv2d(64, 32, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (LeakyReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "      (conv2): ConvBN(\n",
       "        (conv): Conv2d(32, 16, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (LeakyReLU_2): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "    )\n",
       "    (conv_2): ConvBN(\n",
       "      (conv): Conv2d(64, 16, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n",
       "      (bn): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_3): ConvBN(\n",
       "      (conv): Conv2d(32, 16, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n",
       "      (bn): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (relu): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "  )\n",
       "  (decoder_get_feedback_in_UE): Sequential(\n",
       "    (conv1): ConvBN(\n",
       "      (conv): Conv2d(16, 32, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (LeakyReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "    (conv2): ConvBN(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (LeakyReLU_2): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "  )\n",
       "  (remove_AGN): Sequential(\n",
       "    (conv1): ConvBN(\n",
       "      (conv): Conv2d(16, 32, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (LeakyReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "    (conv2): ConvBN(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (LeakyReLU_2): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "  )\n",
       "  (decoder_refine_net): ModuleList(\n",
       "    (0-1): 2 x RefineNet(\n",
       "      (conv): Sequential(\n",
       "        (first_conv1x7): ConvBN(\n",
       "          (conv): Conv2d(2, 8, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n",
       "          (bn): BatchNorm2d(8, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (LeakyReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "        (second_conv1x7): ConvBN(\n",
       "          (conv): Conv2d(8, 16, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n",
       "          (bn): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (LeakyReLU_2): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "        (third_conv1x7): ConvBN(\n",
       "          (conv): Conv2d(16, 2, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n",
       "          (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (conv_1): Sequential(\n",
       "        (first_conv1x5): ConvBN(\n",
       "          (conv): Conv2d(2, 8, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
       "          (bn): BatchNorm2d(8, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (LeakyReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "        (second_conv1x5): ConvBN(\n",
       "          (conv): Conv2d(8, 16, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
       "          (bn): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (LeakyReLU_2): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "        (third_conv1x5): ConvBN(\n",
       "          (conv): Conv2d(16, 2, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
       "          (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (conv1x1): ConvBN(\n",
       "        (conv): Conv2d(4, 2, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n",
       "        (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (_last_cov): Sequential(\n",
       "    (last_conv): ConvBN(\n",
       "      (conv): Conv2d(2, 2, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n",
       "      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (activation): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T18:18:10.692307Z",
     "iopub.status.busy": "2025-04-27T18:18:10.691599Z",
     "iopub.status.idle": "2025-04-27T18:18:10.696381Z",
     "shell.execute_reply": "2025-04-27T18:18:10.695639Z",
     "shell.execute_reply.started": "2025-04-27T18:18:10.692280Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss().to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model._fc_binarization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T18:18:19.468978Z",
     "iopub.status.busy": "2025-04-27T18:18:19.468649Z",
     "iopub.status.idle": "2025-04-27T18:18:19.474121Z",
     "shell.execute_reply": "2025-04-27T18:18:19.473222Z",
     "shell.execute_reply.started": "2025-04-27T18:18:19.468954Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "envir = 'outdoor'  # 'indoor' or 'outdoor'\n",
    "# image params\n",
    "img_height = 32\n",
    "img_width = 32\n",
    "img_channels = 2\n",
    "img_total = img_height * img_width * img_channels\n",
    "# network params\n",
    "#residual_num = 2\n",
    "encoded_dim = 512  # compress rate=1/4->dim.=512, compress rate=1/16->dim.=128, compress rate=1/32->dim.=64, compress rate=1/64->dim.=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T18:18:24.879701Z",
     "iopub.status.busy": "2025-04-27T18:18:24.878983Z",
     "iopub.status.idle": "2025-04-27T18:18:53.930469Z",
     "shell.execute_reply": "2025-04-27T18:18:53.929629Z",
     "shell.execute_reply.started": "2025-04-27T18:18:24.879672Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# envir = 'indoor'  # 'indoor' or 'outdoor'\n",
    "# # image params\n",
    "# img_height = 32\n",
    "# img_width = 32\n",
    "# img_channels = 2\n",
    "# img_total = img_height * img_width * img_channels\n",
    "# # network params\n",
    "# residual_num = 2\n",
    "# encoded_dim = 512  # compress rate=1/4->dim.=512, compress rate=1/16->dim.=128, compress rate=1/32->dim.=64, compress rate=1/64->dim.=32\n",
    "# Data loading\n",
    "#/kaggle/input/cost2100/DATA_HtestFout_all.mat\n",
    "if envir == 'indoor':\n",
    "    mat = sio.loadmat(r'/kaggle/input/cost2100/DATA_Htrainin.mat')\n",
    "    x_train = mat['HT']  # array\n",
    "    mat = sio.loadmat(r'/kaggle/input/cost2100/DATA_Hvalin.mat')\n",
    "    x_val = mat['HT']  # array\n",
    "    mat = sio.loadmat(r'/kaggle/input/cost2100/DATA_Htestin.mat')\n",
    "    x_test = mat['HT']  # array\n",
    "    mat = sio.loadmat(r'/kaggle/input/cost2100/DATA_HtestFin_all.mat')\n",
    "    X_test = mat['HF_all']  # array\n",
    "\n",
    "elif envir == 'outdoor':\n",
    "    mat = sio.loadmat(r'/kaggle/input/cost2100/DATA_Htrainout.mat')\n",
    "    x_train = mat['HT']  # array\n",
    "    mat = sio.loadmat(r'/kaggle/input/cost2100/DATA_Hvalout.mat')\n",
    "    x_val = mat['HT']  # array\n",
    "    mat = sio.loadmat(r'/kaggle/input/cost2100/DATA_Htestout.mat')\n",
    "    x_test = mat['HT']  # array\n",
    "    mat = sio.loadmat(r'/kaggle/input/cost2100/DATA_HtestFout_all.mat')\n",
    "    X_test = mat['HF_all']  # array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T18:19:00.508657Z",
     "iopub.status.busy": "2025-04-27T18:19:00.508326Z",
     "iopub.status.idle": "2025-04-27T18:19:01.809016Z",
     "shell.execute_reply": "2025-04-27T18:19:01.808297Z",
     "shell.execute_reply.started": "2025-04-27T18:19:00.508631Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_val = x_val.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train_length = len(x_train)\n",
    "x_val_length = len(x_val)\n",
    "x_test_length = len(x_test)\n",
    "\n",
    "x_train = np.reshape(x_train, (x_train_length, img_channels, img_height, img_width))  # adapt this if using `channels_first` image data format\n",
    "x_val = np.reshape(x_val, (x_val_length, img_channels, img_height, img_width))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (x_test_length, img_channels, img_height, img_width))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "x_train = torch.tensor(x_train)\n",
    "x_val = torch.tensor(x_val)\n",
    "x_test = torch.tensor(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T18:19:06.464766Z",
     "iopub.status.busy": "2025-04-27T18:19:06.463686Z",
     "iopub.status.idle": "2025-04-27T18:19:53.914516Z",
     "shell.execute_reply": "2025-04-27T18:19:53.913783Z",
     "shell.execute_reply.started": "2025-04-27T18:19:06.464715Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMSE is  -8.28646582291604\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "with torch.no_grad():\n",
    "\n",
    "    #torch.cuda.empty_cache()\n",
    "    model.eval()\n",
    "    device='cpu'\n",
    "    x_hat = model(x_test)\n",
    "    #torch.quantization.convert(quantized_model, inplace=True)\n",
    "    x_test = x_test.to('cpu')\n",
    "    x_hat=x_hat.to('cpu')\n",
    "\n",
    "    # Calcaulating the NMSE and rho\n",
    "    # if envir == 'indoor':\n",
    "    #     mat = sio.loadmat('D:\\Cost2100\\DATA_HtestFin_all.mat')\n",
    "    #     X_test = mat['HF_all']  # array\n",
    "\n",
    "    # elif envir == 'outdoor':\n",
    "    #     mat = sio.loadmat('D:\\Cost2100\\DATA_HtestFout_all.mat')\n",
    "    #     X_test = mat['HF_all']  # array\n",
    "\n",
    "    #X_test = torch.tensor(X_test)\n",
    "    #X_test = torch.reshape(X_test, (len(X_test), img_height, 125))\n",
    "    x_test_real = torch.reshape(x_test[:, 0, :, :], (len(x_test), -1))\n",
    "    x_test_imag = torch.reshape(x_test[:, 1, :, :], (len(x_test), -1))\n",
    "    x_test_C = x_test_real - 0.5 + 1j * (x_test_imag - 0.5)\n",
    "    x_hat_real = torch.reshape(x_hat[:, 0, :, :], (len(x_hat), -1))\n",
    "    x_hat_imag = torch.reshape(x_hat[:, 1, :, :], (len(x_hat), -1))\n",
    "    x_hat_C = x_hat_real - 0.5 + 1j * (x_hat_imag - 0.5)\n",
    "    x_hat_F = torch.reshape(x_hat_C, (len(x_hat_C), img_height, img_width))\n",
    "    X_hat = torch.fft.fft(torch.cat((x_hat_F, torch.zeros((len(x_hat_C), img_height, 257 - img_width))), axis=2), axis=2)\n",
    "    X_hat = X_hat[:, :, 0:125]\n",
    "\n",
    "    #n1 = torch.sqrt(torch.sum(torch.conj(X_test) * X_test, axis=1))\n",
    "    #n2 = torch.sqrt(torch.sum(torch.conj(X_hat) * X_hat, axis=1))\n",
    "    #aa = abs(torch.sum(torch.conj(X_test) * X_hat, axis=1))\n",
    "    #rho = torch.mean(aa / (n1 * n2), axis=1)\n",
    "    X_hat = torch.reshape(X_hat, (len(X_hat), -1))\n",
    "    #X_test = torch.reshape(X_test, (len(X_test), -1))\n",
    "    power = torch.sum(abs(x_test_C) ** 2, axis=1)\n",
    "    power_d = torch.sum(abs(X_hat) ** 2, axis=1)\n",
    "    mse = torch.sum(abs(x_test_C - x_hat_C) ** 2, axis=1)\n",
    "    NMSE = 10 * math.log10(torch.mean(mse / power))\n",
    "    #Correlation = torch.mean(rho).item().real\n",
    "\n",
    "    # print(\"In \" + envir + \" environment\")\n",
    "    # print(\"When dimension is\", encoded_dim)\n",
    "    print(\"NMSE is \", NMSE)\n",
    "    #print(\"Correlation is \", Correlation)\n",
    "#\n",
    "# file = 'CsiNet_' + (envir) + '_dim' + str(encoded_dim) + time.strftime('_%m_%d_%H_%M')\n",
    "# outfile = \"result/result_%s.mat\" % file\n",
    "# savemat(outfile, {'train_loss_history': train_loss_history,\n",
    "#                   'val_loss_history': val_loss_history,\n",
    "#                   'training_time': training_time,\n",
    "#                   'NMSE': NMSE,\n",
    "#                   'Correlation': Correlation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T18:20:08.436677Z",
     "iopub.status.busy": "2025-04-27T18:20:08.436378Z",
     "iopub.status.idle": "2025-04-27T18:20:10.193956Z",
     "shell.execute_reply": "2025-04-27T18:20:10.193159Z",
     "shell.execute_reply.started": "2025-04-27T18:20:08.436654Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Stage 1: Device-Specific Single Sample Benchmark ===\n",
      "Device    Test    Time (ms)           Samples/sec\n",
      "--------  ------  ------------------  ------------------\n",
      "CPU       Single  3.431851863861084   291.38786861124214\n",
      "GPU       Single  3.7399983406066895  267.37979777760637\n",
      "Speedup           0.92x\n",
      "\n",
      "=== Stage 2: Batch Processing Benchmark ===\n",
      "Device      Batch Size    Total (ms)    Per Sample (ms)    Samples/sec\n",
      "--------  ------------  ------------  -----------------  -------------\n",
      "CPU                  1          4.53               4.53         220.82\n",
      "CPU                  8         11.7                1.46         683.49\n",
      "CPU                 16         16.3                1.02         981.32\n",
      "CPU                 32         37.76               1.18         847.43\n",
      "CPU                 64         69.21               1.08         924.75\n",
      "CUDA                 1          4.92               4.92         203.09\n",
      "CUDA                 8          5                  0.63        1599.35\n",
      "CUDA                16          4.08               0.25        3922.66\n",
      "CUDA                32          4.06               0.13        7874.78\n",
      "CUDA                64          4.28               0.07       14950.5\n"
     ]
    }
   ],
   "source": [
    "# ====== ADD THIS NEW CELL FOR TIERED CPU/GPU BENCHMARK ======\n",
    "import time\n",
    "import torch\n",
    "from tabulate import tabulate\n",
    "\n",
    "def run_inference_benchmark(model, input_shape=(2, 32, 32), warmup=10, repetitions=100):\n",
    "    \"\"\"Run comprehensive inference benchmarks on CPU and GPU\"\"\"\n",
    "    results = []\n",
    "    model.eval()\n",
    "    \n",
    "    # CPU Benchmark\n",
    "    device = 'cpu'\n",
    "    model.to(device)\n",
    "    dummy_input = torch.randn(1, *input_shape).to(device)\n",
    "    \n",
    "    # Warm-up\n",
    "    with torch.no_grad():\n",
    "        for _ in range(warmup):\n",
    "            _ = model(dummy_input)\n",
    "    \n",
    "    # Measurement\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(repetitions):\n",
    "            _ = model(dummy_input)\n",
    "    cpu_time = (time.time() - start_time) * 1000 / repetitions\n",
    "    \n",
    "    results.append(('CPU', 'Single', cpu_time, 1000/cpu_time))\n",
    "    \n",
    "    # GPU Benchmark (if available)\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda'\n",
    "        model.to(device)\n",
    "        dummy_input = dummy_input.to(device)\n",
    "        \n",
    "        # Warm-up with synchronization\n",
    "        with torch.no_grad():\n",
    "            for _ in range(warmup):\n",
    "                _ = model(dummy_input)\n",
    "        torch.cuda.synchronize()\n",
    "        \n",
    "        # Measurement\n",
    "        start_time = time.time()\n",
    "        with torch.no_grad():\n",
    "            for _ in range(repetitions):\n",
    "                _ = model(dummy_input)\n",
    "        torch.cuda.synchronize()\n",
    "        gpu_time = (time.time() - start_time) * 1000 / repetitions\n",
    "        \n",
    "        results.append(('GPU', 'Single', gpu_time, 1000/gpu_time))\n",
    "        results.append(('Speedup', '', f\"{cpu_time/gpu_time:.2f}x\", ''))\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run benchmarks\n",
    "print(\"\\n=== Stage 1: Device-Specific Single Sample Benchmark ===\")\n",
    "benchmark_results = run_inference_benchmark(model)\n",
    "\n",
    "# Print formatted results\n",
    "headers = [\"Device\", \"Test\", \"Time (ms)\", \"Samples/sec\"]\n",
    "print(tabulate(benchmark_results, headers=headers, floatfmt=\".2f\"))\n",
    "\n",
    "# Batch Processing Benchmark\n",
    "def batch_benchmark(model, batch_sizes=[1, 8, 16, 32, 64]):\n",
    "    batch_results = []\n",
    "    for device in ['cpu', 'cuda'] if torch.cuda.is_available() else ['cpu']:\n",
    "        if device == 'cuda' and not torch.cuda.is_available():\n",
    "            continue\n",
    "            \n",
    "        model.to(device)\n",
    "        for bs in batch_sizes:\n",
    "            dummy_batch = torch.randn(bs, 2, 32, 32).to(device)\n",
    "            \n",
    "            # Warm-up\n",
    "            with torch.no_grad():\n",
    "                _ = model(dummy_batch)\n",
    "                if device == 'cuda':\n",
    "                    torch.cuda.synchronize()\n",
    "            \n",
    "            # Measure\n",
    "            start = time.time()\n",
    "            with torch.no_grad():\n",
    "                _ = model(dummy_batch)\n",
    "                if device == 'cuda':\n",
    "                    torch.cuda.synchronize()\n",
    "            \n",
    "            total_time = (time.time() - start) * 1000\n",
    "            time_per_sample = total_time / bs\n",
    "            \n",
    "            batch_results.append([\n",
    "                device.upper(),\n",
    "                bs,\n",
    "                f\"{total_time:.2f}\",\n",
    "                f\"{time_per_sample:.2f}\",\n",
    "                f\"{1000/time_per_sample:.2f}\"\n",
    "            ])\n",
    "    return batch_results\n",
    "\n",
    "print(\"\\n=== Stage 2: Batch Processing Benchmark ===\")\n",
    "batch_results = batch_benchmark(model)\n",
    "batch_headers = [\"Device\", \"Batch Size\", \"Total (ms)\", \"Per Sample (ms)\", \"Samples/sec\"]\n",
    "print(tabulate(batch_results, headers=batch_headers))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
