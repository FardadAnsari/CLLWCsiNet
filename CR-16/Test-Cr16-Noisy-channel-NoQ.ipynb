{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6243235,"sourceType":"datasetVersion","datasetId":3587283},{"sourceId":11590626,"sourceType":"datasetVersion","datasetId":7267978}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/cost2100'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2025-04-27T20:17:17.791311Z","iopub.execute_input":"2025-04-27T20:17:17.792069Z","iopub.status.idle":"2025-04-27T20:17:17.798689Z","shell.execute_reply.started":"2025-04-27T20:17:17.792041Z","shell.execute_reply":"2025-04-27T20:17:17.797920Z"},"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/input/cost2100/DATA_Hvalout.mat\n/kaggle/input/cost2100/DATA_Htrainin.mat\n/kaggle/input/cost2100/DATA_HtestFout_all.mat\n/kaggle/input/cost2100/DATA_Htestout.mat\n/kaggle/input/cost2100/DATA_Htestin.mat\n/kaggle/input/cost2100/DATA_Hvalin.mat\n/kaggle/input/cost2100/DATA_Htrainout.mat\n/kaggle/input/cost2100/DATA_HtestFin_all.mat\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"from datetime import datetime\nimport sys\nimport traceback\nfrom datetime import datetime\nimport sys\nimport traceback\nimport scipy.io as sio\nimport torch","metadata":{"execution":{"iopub.status.busy":"2025-04-27T20:17:21.607561Z","iopub.execute_input":"2025-04-27T20:17:21.608120Z","iopub.status.idle":"2025-04-27T20:17:21.611846Z","shell.execute_reply.started":"2025-04-27T20:17:21.608097Z","shell.execute_reply":"2025-04-27T20:17:21.611291Z"},"trusted":true},"outputs":[],"execution_count":54},{"cell_type":"code","source":"class ConvBN(nn.Sequential):\n    def __init__(self, in_planes, out_planes, kernel_size,groups=1):\n        if not isinstance(kernel_size, int):\n            padding = [(i - 1) // 2 for i in kernel_size]\n        else:\n            padding = (kernel_size - 1) // 2\n        super(ConvBN, self).__init__(OrderedDict([\n            ('conv', nn.Conv2d(in_planes, out_planes, kernel_size,\n                               padding=padding)),\n            ('bn', nn.BatchNorm2d(out_planes,eps=1e-03, momentum=0.99))\n        ]))\n\n        \n\nclass RefineNet(nn.Module):\n    def __init__(self, img_channels=2):\n        super(RefineNet, self).__init__()\n        self.conv=nn.Sequential(OrderedDict([\n            (\"first_conv1x7\",ConvBN(img_channels,8,[1,7])),\n            (\"PReLU_1\",nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n            (\"second_Conv1x7\",ConvBN(8,16,[1,7])),\n            (\"PReLU_2\",nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n            (\"third_Conv1x7\",ConvBN(16,2,[1,7])),    \n        ]))\n        \n        self.conv_1=nn.Sequential(OrderedDict([\n            (\"first_conv1x7\",ConvBN(img_channels,8,[1,5])),\n            (\"PReLU_1\",nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n            (\"second_Conv1x7\",ConvBN(8,16,[1,5])),\n            (\"PReLU_2\",nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n            (\"third_Conv1x7\",ConvBN(16,2, [1,5])),    \n        ]))\n        \n        self.conv1x1 = ConvBN(4, 2, [1,7])\n        self.Relu = nn.LeakyReLU(negative_slope=0.3, inplace=True)\n        \n        \n    def forward(self, x):\n        ori_x = x.clone()\n\n        # concatenate\n        x_1 = self.conv(x)\n        x_2 = self.conv_1(x)\n        x = torch.cat((x_1, x_2), dim=1)\n        x = self.Relu(x)\n        x =self.conv1x1(x)\n\n        return self.Relu(x + ori_x)\n    \n    \n    \n    \nclass Encoder_Compression(nn.Module):\n    def __init__(self):\n        super(Encoder_Compression, self).__init__()\n        self.conv=nn.Sequential(OrderedDict([\n            (\"first_conv1x7\",ConvBN(64,32,[1,7])),\n            (\"PReLU_1\",nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n            (\"second_Conv1x7\",ConvBN(32,16,[1,7])),\n            (\"PReLU_2\",nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n            (\"third_Conv1x7\",ConvBN(16,4,[1,7])),\n        ]))\n        \n        self.conv_2=ConvBN(64,4,[1,7])\n        self.conv_3=ConvBN(8,4,[1,7])\n        \n        \n        self.LeakyRelu = nn.LeakyReLU(negative_slope=0.3, inplace=True)\n               \n    def forward(self, x):        \n        # concatenate\n        x_1= self.conv(x)\n        x_2= self.conv_2(x)\n        x = torch.cat((x_1, x_2), dim=1)\n        x = self.LeakyRelu(x)\n        x = self.conv_3(x)\n        #print(\"finish\")\n        ###### Send Feedback From User Equipement\" \n        return self.LeakyRelu(x)\n    \n        \n        \n    \n \n    \n    \n\nclass CLLWCsiNet(nn.Module):\n    def __init__(self,reduction=4,residual_num=2):\n        super(CLLWCsiNet, self).__init__()\n        total_size, in_channel, w, h = 2048, 2, 32, 32\n        \n        self.encoder_p1 = nn.Sequential(OrderedDict([\n            (\"first_conv1x7\",ConvBN(2,2, [1,7])),\n            (\"LeakyReLU_1\",nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n            (\"second_conv1x7\",ConvBN(2,2,[7,1])),\n            #(\"LeakyReLU_2\",nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n            ]))\n        \n        self.encoder_p2= nn.Sequential(OrderedDict([\n            ('conv1x3', ConvBN(2, 2, [1, 5])),\n            ('LeakyRelu_1', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n            ('conv3x1', ConvBN(2, 2, [5, 1])),\n            ]))\n        \n        self.encoder_p3= nn.Sequential(OrderedDict([\n            ('conv1x3', ConvBN(2, 2, [1, 3])),\n            ('LeakyRelu_1', nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n            ('conv3x1', ConvBN(2, 2, [3, 1])),\n            ]))\n        \n        self.con1x1=ConvBN(6, 2, [1,7])\n        self.LeakyReLU=nn.LeakyReLU(negative_slope=0.3, inplace=True)\n        \n        ######################## CNN base Laten Space ########################################\n        self.encoder_compression=Encoder_Compression()\n        \n        \n        \n        self.decoder_get_feedback_in_UE=nn.Sequential(OrderedDict([\n            (\"first_conv1x7\",ConvBN(4,8,[1,7])),\n            (\"LeakyRelu_1\",nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n            (\"conv1x7\",ConvBN(8,16,[1,7])),\n            (\"LeakyRelu_2\",nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n            (\"second_conv1x7\",ConvBN(16,64,[1,7])),\n             #(\"LeakyRelu_3\",nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n            ]))\n        \n        \n        self.remove_AGN=nn.Sequential(OrderedDict([\n            (\"conv_1x7\",ConvBN(4,8,[1,7])),\n            (\"LeakyReLu_1\",nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n            (\"conv_7x1\",ConvBN(8,16,[1,7])),\n            (\"LeakyReLu_1\",nn.LeakyReLU(negative_slope=0.3, inplace=True)),\n            (\"conv_3x3\",ConvBN(16,64,[1,7])),\n        ]))\n        \n        \n        ###################################    refine Module #########################################\n#         self.refine =  nn.Sequential(OrderedDict([\n#             (\"MultiResolutionRefineBlock\", MultiResolutionRefineBlock()),\n#             (\"MultiResolutionRefineBlock\", MultiResolutionRefineBlock())\n#         ]))\n        \n        \n        self.decoder_refine_net = nn.ModuleList([RefineNet(in_channel) for _ in range(residual_num)])\n        \n        self._last_cov=nn.Sequential(OrderedDict([\n            (\"firstcov2\",ConvBN(2,2,[1,7])),\n            (\"activation\",nn.Sigmoid())\n        ]))\n        \n        \n        \n        for m in self.modules():\n            if isinstance(m, (nn.Conv2d)):\n                nn.init.xavier_uniform_(m.weight)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n        \n        \n    def adding_noise(self, x):\n        # Ensure input is normalized to [0, 1]\n        #assert x.min() >= 0 and x.max() <= 1, \"Input must be in [0, 1] range. Normalize first!\"\n        \n        # Compute signal power (assumes [0,1] range)\n        signal_power = torch.mean(x**2)\n        \n        # Set SNR (e.g., 20 dB)\n        snr_db = -10 \n        snr_linear = 10 ** (snr_db / 10)\n        \n        # Calculate noise power\n        noise_power = signal_power / snr_linear\n        \n        # Generate noise\n        noise = torch.randn_like(x) * torch.sqrt(noise_power)\n        \n        # Add noise and clip to maintain [0,1] range\n        noisy_x = torch.clamp(x + noise, 0, 1)\n        \n        return noisy_x\n    \n    \n    \n    def forward(self, x):\n        batch_size, channels, height, width = x.size()\n        #print(x.size())\n        x_1=self.encoder_p1(x)\n        x_2=self.encoder_p2(x)\n        x_3=self.encoder_p3(x)\n        x=torch.cat((x_1,x_2,x_3),dim=1)\n        x=self.con1x1(x)\n        x=self.LeakyReLU(x)\n        #print(x.size())\n        x = x.contiguous().view(batch_size,64 ,1,32)\n        #print(x.size())\n        x=self.encoder_compression(x)\n        x_noisy_feedback=self.adding_noise(x)\n        y=self.remove_AGN(x_noisy_feedback)\n        x=self.decoder_get_feedback_in_UE(x)\n        x=x-y\n        x=self.LeakyReLU(x)\n        x = x.contiguous().view(batch_size,2 ,32,32)\n        #x = self.refine(x)\n        for layer in self.decoder_refine_net:\n            x = layer(x)\n        x=self._last_cov(x)\n       \n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2025-04-27T20:17:27.797834Z","iopub.execute_input":"2025-04-27T20:17:27.798320Z","iopub.status.idle":"2025-04-27T20:17:27.818796Z","shell.execute_reply.started":"2025-04-27T20:17:27.798297Z","shell.execute_reply":"2025-04-27T20:17:27.818279Z"},"trusted":true},"outputs":[],"execution_count":55},{"cell_type":"code","source":"model = CLLWCsiNet()","metadata":{"execution":{"iopub.status.busy":"2025-04-27T20:17:40.088550Z","iopub.execute_input":"2025-04-27T20:17:40.089072Z","iopub.status.idle":"2025-04-27T20:17:40.104747Z","shell.execute_reply.started":"2025-04-27T20:17:40.089050Z","shell.execute_reply":"2025-04-27T20:17:40.104211Z"},"trusted":true},"outputs":[],"execution_count":56},{"cell_type":"code","source":"pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)","metadata":{"execution":{"iopub.status.busy":"2025-04-27T20:17:42.517659Z","iopub.execute_input":"2025-04-27T20:17:42.518199Z","iopub.status.idle":"2025-04-27T20:17:42.522251Z","shell.execute_reply.started":"2025-04-27T20:17:42.518175Z","shell.execute_reply":"2025-04-27T20:17:42.521511Z"},"trusted":true},"outputs":[],"execution_count":57},{"cell_type":"code","source":"pytorch_total_params","metadata":{"execution":{"iopub.status.busy":"2025-04-27T20:17:45.116356Z","iopub.execute_input":"2025-04-27T20:17:45.116808Z","iopub.status.idle":"2025-04-27T20:17:45.121253Z","shell.execute_reply.started":"2025-04-27T20:17:45.116786Z","shell.execute_reply":"2025-04-27T20:17:45.120611Z"},"trusted":true},"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"42608"},"metadata":{}}],"execution_count":58},{"cell_type":"code","source":"import torch\n#from Trans_Net.utils import *\n\n\nstate_dict = torch.load(r'/kaggle/input/cllwcsinet-noisy-channel/CLLWCsiNet-noisy-channel/cr16/outdoor/CLLWCsiNet_Net_model_500_outdoor_128_.pth',map_location=torch.device('cpu'))['model_state_dict']","metadata":{"execution":{"iopub.status.busy":"2025-04-27T20:22:01.502319Z","iopub.execute_input":"2025-04-27T20:22:01.502966Z","iopub.status.idle":"2025-04-27T20:22:01.560784Z","shell.execute_reply.started":"2025-04-27T20:22:01.502938Z","shell.execute_reply":"2025-04-27T20:22:01.560082Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/513177726.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state_dict = torch.load(r'/kaggle/input/cllwcsinet-noisy-channel/CLLWCsiNet-noisy-channel/cr16/outdoor/CLLWCsiNet_Net_model_500_outdoor_128_.pth',map_location=torch.device('cpu'))['model_state_dict']\n","output_type":"stream"}],"execution_count":69},{"cell_type":"code","source":"model.load_state_dict(state_dict)","metadata":{"execution":{"iopub.status.busy":"2025-04-27T20:22:05.029648Z","iopub.execute_input":"2025-04-27T20:22:05.029937Z","iopub.status.idle":"2025-04-27T20:22:05.041124Z","shell.execute_reply.started":"2025-04-27T20:22:05.029918Z","shell.execute_reply":"2025-04-27T20:22:05.040599Z"},"trusted":true},"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":70},{"cell_type":"code","source":"model.eval()","metadata":{"execution":{"iopub.status.busy":"2025-04-27T20:22:07.279236Z","iopub.execute_input":"2025-04-27T20:22:07.279975Z","iopub.status.idle":"2025-04-27T20:22:07.289485Z","shell.execute_reply.started":"2025-04-27T20:22:07.279942Z","shell.execute_reply":"2025-04-27T20:22:07.288626Z"},"trusted":true},"outputs":[{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"CLLWCsiNet(\n  (encoder_p1): Sequential(\n    (first_conv1x7): ConvBN(\n      (conv): Conv2d(2, 2, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (LeakyReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n    (second_conv1x7): ConvBN(\n      (conv): Conv2d(2, 2, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0))\n      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n  )\n  (encoder_p2): Sequential(\n    (conv1x3): ConvBN(\n      (conv): Conv2d(2, 2, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (LeakyRelu_1): LeakyReLU(negative_slope=0.3, inplace=True)\n    (conv3x1): ConvBN(\n      (conv): Conv2d(2, 2, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n  )\n  (encoder_p3): Sequential(\n    (conv1x3): ConvBN(\n      (conv): Conv2d(2, 2, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (LeakyRelu_1): LeakyReLU(negative_slope=0.3, inplace=True)\n    (conv3x1): ConvBN(\n      (conv): Conv2d(2, 2, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n  )\n  (con1x1): ConvBN(\n    (conv): Conv2d(6, 2, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n    (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n  )\n  (LeakyReLU): LeakyReLU(negative_slope=0.3, inplace=True)\n  (encoder_compression): Encoder_Compression(\n    (conv): Sequential(\n      (first_conv1x7): ConvBN(\n        (conv): Conv2d(64, 32, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n      )\n      (PReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n      (second_Conv1x7): ConvBN(\n        (conv): Conv2d(32, 16, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n        (bn): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n      )\n      (PReLU_2): LeakyReLU(negative_slope=0.3, inplace=True)\n      (third_Conv1x7): ConvBN(\n        (conv): Conv2d(16, 4, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n        (bn): BatchNorm2d(4, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n      )\n    )\n    (conv_2): ConvBN(\n      (conv): Conv2d(64, 4, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n      (bn): BatchNorm2d(4, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (conv_3): ConvBN(\n      (conv): Conv2d(8, 4, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n      (bn): BatchNorm2d(4, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (LeakyRelu): LeakyReLU(negative_slope=0.3, inplace=True)\n  )\n  (decoder_get_feedback_in_UE): Sequential(\n    (first_conv1x7): ConvBN(\n      (conv): Conv2d(4, 8, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n      (bn): BatchNorm2d(8, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (LeakyRelu_1): LeakyReLU(negative_slope=0.3, inplace=True)\n    (conv1x7): ConvBN(\n      (conv): Conv2d(8, 16, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n      (bn): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (LeakyRelu_2): LeakyReLU(negative_slope=0.3, inplace=True)\n    (second_conv1x7): ConvBN(\n      (conv): Conv2d(16, 64, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n  )\n  (remove_AGN): Sequential(\n    (conv_1x7): ConvBN(\n      (conv): Conv2d(4, 8, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n      (bn): BatchNorm2d(8, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (LeakyReLu_1): LeakyReLU(negative_slope=0.3, inplace=True)\n    (conv_7x1): ConvBN(\n      (conv): Conv2d(8, 16, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n      (bn): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (conv_3x3): ConvBN(\n      (conv): Conv2d(16, 64, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n  )\n  (decoder_refine_net): ModuleList(\n    (0-1): 2 x RefineNet(\n      (conv): Sequential(\n        (first_conv1x7): ConvBN(\n          (conv): Conv2d(2, 8, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n          (bn): BatchNorm2d(8, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n        )\n        (PReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n        (second_Conv1x7): ConvBN(\n          (conv): Conv2d(8, 16, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n          (bn): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n        )\n        (PReLU_2): LeakyReLU(negative_slope=0.3, inplace=True)\n        (third_Conv1x7): ConvBN(\n          (conv): Conv2d(16, 2, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n          (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n        )\n      )\n      (conv_1): Sequential(\n        (first_conv1x7): ConvBN(\n          (conv): Conv2d(2, 8, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n          (bn): BatchNorm2d(8, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n        )\n        (PReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n        (second_Conv1x7): ConvBN(\n          (conv): Conv2d(8, 16, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n          (bn): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n        )\n        (PReLU_2): LeakyReLU(negative_slope=0.3, inplace=True)\n        (third_Conv1x7): ConvBN(\n          (conv): Conv2d(16, 2, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n          (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n        )\n      )\n      (conv1x1): ConvBN(\n        (conv): Conv2d(4, 2, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n        (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n      )\n      (Relu): LeakyReLU(negative_slope=0.3, inplace=True)\n    )\n  )\n  (_last_cov): Sequential(\n    (firstcov2): ConvBN(\n      (conv): Conv2d(2, 2, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (activation): Sigmoid()\n  )\n)"},"metadata":{}}],"execution_count":71},{"cell_type":"code","source":"model.to('cpu')","metadata":{"execution":{"iopub.status.busy":"2025-04-27T20:22:14.296066Z","iopub.execute_input":"2025-04-27T20:22:14.296530Z","iopub.status.idle":"2025-04-27T20:22:14.308929Z","shell.execute_reply.started":"2025-04-27T20:22:14.296507Z","shell.execute_reply":"2025-04-27T20:22:14.308222Z"},"trusted":true},"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"CLLWCsiNet(\n  (encoder_p1): Sequential(\n    (first_conv1x7): ConvBN(\n      (conv): Conv2d(2, 2, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (LeakyReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n    (second_conv1x7): ConvBN(\n      (conv): Conv2d(2, 2, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0))\n      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n  )\n  (encoder_p2): Sequential(\n    (conv1x3): ConvBN(\n      (conv): Conv2d(2, 2, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (LeakyRelu_1): LeakyReLU(negative_slope=0.3, inplace=True)\n    (conv3x1): ConvBN(\n      (conv): Conv2d(2, 2, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n  )\n  (encoder_p3): Sequential(\n    (conv1x3): ConvBN(\n      (conv): Conv2d(2, 2, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (LeakyRelu_1): LeakyReLU(negative_slope=0.3, inplace=True)\n    (conv3x1): ConvBN(\n      (conv): Conv2d(2, 2, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n  )\n  (con1x1): ConvBN(\n    (conv): Conv2d(6, 2, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n    (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n  )\n  (LeakyReLU): LeakyReLU(negative_slope=0.3, inplace=True)\n  (encoder_compression): Encoder_Compression(\n    (conv): Sequential(\n      (first_conv1x7): ConvBN(\n        (conv): Conv2d(64, 32, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n      )\n      (PReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n      (second_Conv1x7): ConvBN(\n        (conv): Conv2d(32, 16, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n        (bn): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n      )\n      (PReLU_2): LeakyReLU(negative_slope=0.3, inplace=True)\n      (third_Conv1x7): ConvBN(\n        (conv): Conv2d(16, 4, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n        (bn): BatchNorm2d(4, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n      )\n    )\n    (conv_2): ConvBN(\n      (conv): Conv2d(64, 4, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n      (bn): BatchNorm2d(4, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (conv_3): ConvBN(\n      (conv): Conv2d(8, 4, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n      (bn): BatchNorm2d(4, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (LeakyRelu): LeakyReLU(negative_slope=0.3, inplace=True)\n  )\n  (decoder_get_feedback_in_UE): Sequential(\n    (first_conv1x7): ConvBN(\n      (conv): Conv2d(4, 8, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n      (bn): BatchNorm2d(8, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (LeakyRelu_1): LeakyReLU(negative_slope=0.3, inplace=True)\n    (conv1x7): ConvBN(\n      (conv): Conv2d(8, 16, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n      (bn): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (LeakyRelu_2): LeakyReLU(negative_slope=0.3, inplace=True)\n    (second_conv1x7): ConvBN(\n      (conv): Conv2d(16, 64, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n  )\n  (remove_AGN): Sequential(\n    (conv_1x7): ConvBN(\n      (conv): Conv2d(4, 8, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n      (bn): BatchNorm2d(8, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (LeakyReLu_1): LeakyReLU(negative_slope=0.3, inplace=True)\n    (conv_7x1): ConvBN(\n      (conv): Conv2d(8, 16, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n      (bn): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (conv_3x3): ConvBN(\n      (conv): Conv2d(16, 64, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n  )\n  (decoder_refine_net): ModuleList(\n    (0-1): 2 x RefineNet(\n      (conv): Sequential(\n        (first_conv1x7): ConvBN(\n          (conv): Conv2d(2, 8, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n          (bn): BatchNorm2d(8, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n        )\n        (PReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n        (second_Conv1x7): ConvBN(\n          (conv): Conv2d(8, 16, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n          (bn): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n        )\n        (PReLU_2): LeakyReLU(negative_slope=0.3, inplace=True)\n        (third_Conv1x7): ConvBN(\n          (conv): Conv2d(16, 2, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n          (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n        )\n      )\n      (conv_1): Sequential(\n        (first_conv1x7): ConvBN(\n          (conv): Conv2d(2, 8, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n          (bn): BatchNorm2d(8, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n        )\n        (PReLU_1): LeakyReLU(negative_slope=0.3, inplace=True)\n        (second_Conv1x7): ConvBN(\n          (conv): Conv2d(8, 16, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n          (bn): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n        )\n        (PReLU_2): LeakyReLU(negative_slope=0.3, inplace=True)\n        (third_Conv1x7): ConvBN(\n          (conv): Conv2d(16, 2, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n          (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n        )\n      )\n      (conv1x1): ConvBN(\n        (conv): Conv2d(4, 2, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n        (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n      )\n      (Relu): LeakyReLU(negative_slope=0.3, inplace=True)\n    )\n  )\n  (_last_cov): Sequential(\n    (firstcov2): ConvBN(\n      (conv): Conv2d(2, 2, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n      (bn): BatchNorm2d(2, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n    )\n    (activation): Sigmoid()\n  )\n)"},"metadata":{}}],"execution_count":72},{"cell_type":"code","source":"criterion = nn.MSELoss().to('cpu')","metadata":{"execution":{"iopub.status.busy":"2025-04-27T20:22:22.857641Z","iopub.execute_input":"2025-04-27T20:22:22.857949Z","iopub.status.idle":"2025-04-27T20:22:22.861910Z","shell.execute_reply.started":"2025-04-27T20:22:22.857929Z","shell.execute_reply":"2025-04-27T20:22:22.861195Z"},"trusted":true},"outputs":[],"execution_count":73},{"cell_type":"code","source":"model._fc_binarization()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"envir = 'outdoor'  # 'indoor' or 'outdoor'\n# image params\nimg_height = 32\nimg_width = 32\nimg_channels = 2\nimg_total = img_height * img_width * img_channels\n# network params\n#residual_num = 2\nencoded_dim = 512  # compress rate=1/4->dim.=512, compress rate=1/16->dim.=128, compress rate=1/32->dim.=64, compress rate=1/64->dim.=32","metadata":{"execution":{"iopub.status.busy":"2025-04-27T20:22:31.079575Z","iopub.execute_input":"2025-04-27T20:22:31.079850Z","iopub.status.idle":"2025-04-27T20:22:31.083678Z","shell.execute_reply.started":"2025-04-27T20:22:31.079832Z","shell.execute_reply":"2025-04-27T20:22:31.083027Z"},"trusted":true},"outputs":[],"execution_count":74},{"cell_type":"code","source":"# envir = 'indoor'  # 'indoor' or 'outdoor'\n# # image params\n# img_height = 32\n# img_width = 32\n# img_channels = 2\n# img_total = img_height * img_width * img_channels\n# # network params\n# residual_num = 2\n# encoded_dim = 512  # compress rate=1/4->dim.=512, compress rate=1/16->dim.=128, compress rate=1/32->dim.=64, compress rate=1/64->dim.=32\n# Data loading\n#/kaggle/input/cost2100/DATA_HtestFout_all.mat\nif envir == 'indoor':\n    mat = sio.loadmat(r'/kaggle/input/cost2100/DATA_Htrainin.mat')\n    x_train = mat['HT']  # array\n    mat = sio.loadmat(r'/kaggle/input/cost2100/DATA_Hvalin.mat')\n    x_val = mat['HT']  # array\n    mat = sio.loadmat(r'/kaggle/input/cost2100/DATA_Htestin.mat')\n    x_test = mat['HT']  # array\n    mat = sio.loadmat(r'/kaggle/input/cost2100/DATA_HtestFin_all.mat')\n    X_test = mat['HF_all']  # array\n\nelif envir == 'outdoor':\n    mat = sio.loadmat(r'/kaggle/input/cost2100/DATA_Htrainout.mat')\n    x_train = mat['HT']  # array\n    mat = sio.loadmat(r'/kaggle/input/cost2100/DATA_Hvalout.mat')\n    x_val = mat['HT']  # array\n    mat = sio.loadmat(r'/kaggle/input/cost2100/DATA_Htestout.mat')\n    x_test = mat['HT']  # array\n    mat = sio.loadmat(r'/kaggle/input/cost2100/DATA_HtestFout_all.mat')\n    X_test = mat['HF_all']  # array","metadata":{"execution":{"iopub.status.busy":"2025-04-27T20:22:34.045506Z","iopub.execute_input":"2025-04-27T20:22:34.046058Z","iopub.status.idle":"2025-04-27T20:22:58.703005Z","shell.execute_reply.started":"2025-04-27T20:22:34.046032Z","shell.execute_reply":"2025-04-27T20:22:58.702424Z"},"trusted":true},"outputs":[],"execution_count":75},{"cell_type":"code","source":"import numpy as np\n\nx_train = x_train.astype('float32')\nx_val = x_val.astype('float32')\nx_test = x_test.astype('float32')\n\nx_train_length = len(x_train)\nx_val_length = len(x_val)\nx_test_length = len(x_test)\n\nx_train = np.reshape(x_train, (x_train_length, img_channels, img_height, img_width))  # adapt this if using `channels_first` image data format\nx_val = np.reshape(x_val, (x_val_length, img_channels, img_height, img_width))  # adapt this if using `channels_first` image data format\nx_test = np.reshape(x_test, (x_test_length, img_channels, img_height, img_width))  # adapt this if using `channels_first` image data format\n\nx_train = torch.tensor(x_train)\nx_val = torch.tensor(x_val)\nx_test = torch.tensor(x_test)","metadata":{"execution":{"iopub.status.busy":"2025-04-27T20:23:03.280385Z","iopub.execute_input":"2025-04-27T20:23:03.280921Z","iopub.status.idle":"2025-04-27T20:23:04.683415Z","shell.execute_reply.started":"2025-04-27T20:23:03.280898Z","shell.execute_reply":"2025-04-27T20:23:04.682123Z"},"trusted":true},"outputs":[],"execution_count":76},{"cell_type":"code","source":"import math\nwith torch.no_grad():\n\n    #torch.cuda.empty_cache()\n    model.eval()\n    device='cpu'\n    x_hat = model(x_test)\n    #torch.quantization.convert(quantized_model, inplace=True)\n    x_test = x_test.to('cpu')\n    x_hat=x_hat.to('cpu')\n\n    # Calcaulating the NMSE and rho\n    # if envir == 'indoor':\n    #     mat = sio.loadmat('D:\\Cost2100\\DATA_HtestFin_all.mat')\n    #     X_test = mat['HF_all']  # array\n\n    # elif envir == 'outdoor':\n    #     mat = sio.loadmat('D:\\Cost2100\\DATA_HtestFout_all.mat')\n    #     X_test = mat['HF_all']  # array\n\n    #X_test = torch.tensor(X_test)\n    #X_test = torch.reshape(X_test, (len(X_test), img_height, 125))\n    x_test_real = torch.reshape(x_test[:, 0, :, :], (len(x_test), -1))\n    x_test_imag = torch.reshape(x_test[:, 1, :, :], (len(x_test), -1))\n    x_test_C = x_test_real - 0.5 + 1j * (x_test_imag - 0.5)\n    x_hat_real = torch.reshape(x_hat[:, 0, :, :], (len(x_hat), -1))\n    x_hat_imag = torch.reshape(x_hat[:, 1, :, :], (len(x_hat), -1))\n    x_hat_C = x_hat_real - 0.5 + 1j * (x_hat_imag - 0.5)\n    x_hat_F = torch.reshape(x_hat_C, (len(x_hat_C), img_height, img_width))\n    X_hat = torch.fft.fft(torch.cat((x_hat_F, torch.zeros((len(x_hat_C), img_height, 257 - img_width))), axis=2), axis=2)\n    X_hat = X_hat[:, :, 0:125]\n\n    #n1 = torch.sqrt(torch.sum(torch.conj(X_test) * X_test, axis=1))\n    #n2 = torch.sqrt(torch.sum(torch.conj(X_hat) * X_hat, axis=1))\n    #aa = abs(torch.sum(torch.conj(X_test) * X_hat, axis=1))\n    #rho = torch.mean(aa / (n1 * n2), axis=1)\n    X_hat = torch.reshape(X_hat, (len(X_hat), -1))\n    #X_test = torch.reshape(X_test, (len(X_test), -1))\n    power = torch.sum(abs(x_test_C) ** 2, axis=1)\n    power_d = torch.sum(abs(X_hat) ** 2, axis=1)\n    mse = torch.sum(abs(x_test_C - x_hat_C) ** 2, axis=1)\n    NMSE = 10 * math.log10(torch.mean(mse / power))\n    #Correlation = torch.mean(rho).item().real\n\n    # print(\"In \" + envir + \" environment\")\n    # print(\"When dimension is\", encoded_dim)\n    print(\"NMSE is \", NMSE)\n    #print(\"Correlation is \", Correlation)\n#\n# file = 'CsiNet_' + (envir) + '_dim' + str(encoded_dim) + time.strftime('_%m_%d_%H_%M')\n# outfile = \"result/result_%s.mat\" % file\n# savemat(outfile, {'train_loss_history': train_loss_history,\n#                   'val_loss_history': val_loss_history,\n#                   'training_time': training_time,\n#                   'NMSE': NMSE,\n#                   'Correlation': Correlation})","metadata":{"execution":{"iopub.status.busy":"2025-04-27T20:23:08.102262Z","iopub.execute_input":"2025-04-27T20:23:08.102516Z","iopub.status.idle":"2025-04-27T20:23:48.750855Z","shell.execute_reply.started":"2025-04-27T20:23:08.102498Z","shell.execute_reply":"2025-04-27T20:23:48.750072Z"},"trusted":true},"outputs":[{"name":"stdout","text":"NMSE is  -2.088769005431192\n","output_type":"stream"}],"execution_count":77},{"cell_type":"code","source":"# ====== ADD THIS NEW CELL FOR TIERED CPU/GPU BENCHMARK ======\nimport time\nimport torch\nfrom tabulate import tabulate\n\ndef run_inference_benchmark(model, input_shape=(2, 32, 32), warmup=10, repetitions=100):\n    \"\"\"Run comprehensive inference benchmarks on CPU and GPU\"\"\"\n    results = []\n    model.eval()\n    \n    # CPU Benchmark\n    device = 'cpu'\n    model.to(device)\n    dummy_input = torch.randn(1, *input_shape).to(device)\n    \n    # Warm-up\n    with torch.no_grad():\n        for _ in range(warmup):\n            _ = model(dummy_input)\n    \n    # Measurement\n    start_time = time.time()\n    with torch.no_grad():\n        for _ in range(repetitions):\n            _ = model(dummy_input)\n    cpu_time = (time.time() - start_time) * 1000 / repetitions\n    \n    results.append(('CPU', 'Single', cpu_time, 1000/cpu_time))\n    \n    # GPU Benchmark (if available)\n    if torch.cuda.is_available():\n        device = 'cuda'\n        model.to(device)\n        dummy_input = dummy_input.to(device)\n        \n        # Warm-up with synchronization\n        with torch.no_grad():\n            for _ in range(warmup):\n                _ = model(dummy_input)\n        torch.cuda.synchronize()\n        \n        # Measurement\n        start_time = time.time()\n        with torch.no_grad():\n            for _ in range(repetitions):\n                _ = model(dummy_input)\n        torch.cuda.synchronize()\n        gpu_time = (time.time() - start_time) * 1000 / repetitions\n        \n        results.append(('GPU', 'Single', gpu_time, 1000/gpu_time))\n        results.append(('Speedup', '', f\"{cpu_time/gpu_time:.2f}x\", ''))\n    \n    return results\n\n# Run benchmarks\nprint(\"\\n=== Stage 1: Device-Specific Single Sample Benchmark ===\")\nbenchmark_results = run_inference_benchmark(model)\n\n# Print formatted results\nheaders = [\"Device\", \"Test\", \"Time (ms)\", \"Samples/sec\"]\nprint(tabulate(benchmark_results, headers=headers, floatfmt=\".2f\"))\n\n# Batch Processing Benchmark\ndef batch_benchmark(model, batch_sizes=[1, 8, 16, 32, 64]):\n    batch_results = []\n    for device in ['cpu', 'cuda'] if torch.cuda.is_available() else ['cpu']:\n        if device == 'cuda' and not torch.cuda.is_available():\n            continue\n            \n        model.to(device)\n        for bs in batch_sizes:\n            dummy_batch = torch.randn(bs, 2, 32, 32).to(device)\n            \n            # Warm-up\n            with torch.no_grad():\n                _ = model(dummy_batch)\n                if device == 'cuda':\n                    torch.cuda.synchronize()\n            \n            # Measure\n            start = time.time()\n            with torch.no_grad():\n                _ = model(dummy_batch)\n                if device == 'cuda':\n                    torch.cuda.synchronize()\n            \n            total_time = (time.time() - start) * 1000\n            time_per_sample = total_time / bs\n            \n            batch_results.append([\n                device.upper(),\n                bs,\n                f\"{total_time:.2f}\",\n                f\"{time_per_sample:.2f}\",\n                f\"{1000/time_per_sample:.2f}\"\n            ])\n    return batch_results\n\nprint(\"\\n=== Stage 2: Batch Processing Benchmark ===\")\nbatch_results = batch_benchmark(model)\nbatch_headers = [\"Device\", \"Batch Size\", \"Total (ms)\", \"Per Sample (ms)\", \"Samples/sec\"]\nprint(tabulate(batch_results, headers=batch_headers))","metadata":{"execution":{"iopub.status.busy":"2025-04-27T20:23:59.230576Z","iopub.execute_input":"2025-04-27T20:23:59.231064Z","iopub.status.idle":"2025-04-27T20:24:00.257602Z","shell.execute_reply.started":"2025-04-27T20:23:59.231044Z","shell.execute_reply":"2025-04-27T20:24:00.256914Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\n=== Stage 1: Device-Specific Single Sample Benchmark ===\nDevice    Test    Time (ms)           Samples/sec\n--------  ------  ------------------  ------------------\nCPU       Single  3.2305550575256348  309.54432974930495\nGPU       Single  4.014348983764648   249.10639409885135\nSpeedup           0.80x\n\n=== Stage 2: Batch Processing Benchmark ===\nDevice      Batch Size    Total (ms)    Per Sample (ms)    Samples/sec\n--------  ------------  ------------  -----------------  -------------\nCPU                  1          3.1                3.1          322.32\nCPU                  8          8.41               1.05         951.44\nCPU                 16         11.83               0.74        1352.76\nCPU                 32         16.05               0.5         1993.96\nCPU                 64         29.99               0.47        2134.2\nCUDA                 1          4.08               4.08         245.05\nCUDA                 8          3.97               0.5         2014.56\nCUDA                16          4.05               0.25        3950.83\nCUDA                32          4.03               0.13        7932.96\nCUDA                64          4.89               0.08       13086.1\n","output_type":"stream"}],"execution_count":78}]}